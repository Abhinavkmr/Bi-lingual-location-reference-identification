{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-2-3-2-2-CNN_multifilter(256-128-64_CRF_Bilingual.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fKUdjwBkLxK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "outputId": "21856ba9-9bb9-4ba0-f65b-85e7e9ea4539"
      },
      "source": [
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 26kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.28.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 38.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 55.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (46.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow 2.2.0rc3\n",
            "    Uninstalling tensorflow-2.2.0rc3:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc3\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q86roTgo_tMa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejnUUOgHa_FE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "f6ff3fcb-83dc-4751-f1b2-7b9a794e3068"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6jQd_jBbE08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "2901e4d4-8be9-4805-96b2-e24758d39a5c"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2pPHVYf6qqD"
      },
      "source": [
        "# Installing fasttext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeXEu9libQy1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "61abfb6c-52d0-45db-9bbb-000c2ae525c1"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/84)\u001b[K\rremote: Counting objects:   2% (2/84)\u001b[K\rremote: Counting objects:   3% (3/84)\u001b[K\rremote: Counting objects:   4% (4/84)\u001b[K\rremote: Counting objects:   5% (5/84)\u001b[K\rremote: Counting objects:   7% (6/84)\u001b[K\rremote: Counting objects:   8% (7/84)\u001b[K\rremote: Counting objects:   9% (8/84)\u001b[K\rremote: Counting objects:  10% (9/84)\u001b[K\rremote: Counting objects:  11% (10/84)\u001b[K\rremote: Counting objects:  13% (11/84)\u001b[K\rremote: Counting objects:  14% (12/84)\u001b[K\rremote: Counting objects:  15% (13/84)\u001b[K\rremote: Counting objects:  16% (14/84)\u001b[K\rremote: Counting objects:  17% (15/84)\u001b[K\rremote: Counting objects:  19% (16/84)\u001b[K\rremote: Counting objects:  20% (17/84)\u001b[K\rremote: Counting objects:  21% (18/84)\u001b[K\rremote: Counting objects:  22% (19/84)\u001b[K\rremote: Counting objects:  23% (20/84)\u001b[K\rremote: Counting objects:  25% (21/84)\u001b[K\rremote: Counting objects:  26% (22/84)\u001b[K\rremote: Counting objects:  27% (23/84)\u001b[K\rremote: Counting objects:  28% (24/84)\u001b[K\rremote: Counting objects:  29% (25/84)\u001b[K\rremote: Counting objects:  30% (26/84)\u001b[K\rremote: Counting objects:  32% (27/84)\u001b[K\rremote: Counting objects:  33% (28/84)\u001b[K\rremote: Counting objects:  34% (29/84)\u001b[K\rremote: Counting objects:  35% (30/84)\u001b[K\rremote: Counting objects:  36% (31/84)\u001b[K\rremote: Counting objects:  38% (32/84)\u001b[K\rremote: Counting objects:  39% (33/84)\u001b[K\rremote: Counting objects:  40% (34/84)\u001b[K\rremote: Counting objects:  41% (35/84)\u001b[K\rremote: Counting objects:  42% (36/84)\u001b[K\rremote: Counting objects:  44% (37/84)\u001b[K\rremote: Counting objects:  45% (38/84)\u001b[K\rremote: Counting objects:  46% (39/84)\u001b[K\rremote: Counting objects:  47% (40/84)\u001b[K\rremote: Counting objects:  48% (41/84)\u001b[K\rremote: Counting objects:  50% (42/84)\u001b[K\rremote: Counting objects:  51% (43/84)\u001b[K\rremote: Counting objects:  52% (44/84)\u001b[K\rremote: Counting objects:  53% (45/84)\u001b[K\rremote: Counting objects:  54% (46/84)\u001b[K\rremote: Counting objects:  55% (47/84)\u001b[K\rremote: Counting objects:  57% (48/84)\u001b[K\rremote: Counting objects:  58% (49/84)\u001b[K\rremote: Counting objects:  59% (50/84)\u001b[K\rremote: Counting objects:  60% (51/84)\u001b[K\rremote: Counting objects:  61% (52/84)\u001b[K\rremote: Counting objects:  63% (53/84)\u001b[K\rremote: Counting objects:  64% (54/84)\u001b[K\rremote: Counting objects:  65% (55/84)\u001b[K\rremote: Counting objects:  66% (56/84)\u001b[K\rremote: Counting objects:  67% (57/84)\u001b[K\rremote: Counting objects:  69% (58/84)\u001b[K\rremote: Counting objects:  70% (59/84)\u001b[K\rremote: Counting objects:  71% (60/84)\u001b[K\rremote: Counting objects:  72% (61/84)\u001b[K\rremote: Counting objects:  73% (62/84)\u001b[K\rremote: Counting objects:  75% (63/84)\u001b[K\rremote: Counting objects:  76% (64/84)\u001b[K\rremote: Counting objects:  77% (65/84)\u001b[K\rremote: Counting objects:  78% (66/84)\u001b[K\rremote: Counting objects:  79% (67/84)\u001b[K\rremote: Counting objects:  80% (68/84)\u001b[K\rremote: Counting objects:  82% (69/84)\u001b[K\rremote: Counting objects:  83% (70/84)\u001b[K\rremote: Counting objects:  84% (71/84)\u001b[K\rremote: Counting objects:  85% (72/84)\u001b[K\rremote: Counting objects:  86% (73/84)\u001b[K\rremote: Counting objects:  88% (74/84)\u001b[K\rremote: Counting objects:  89% (75/84)\u001b[K\rremote: Counting objects:  90% (76/84)\u001b[K\rremote: Counting objects:  91% (77/84)\u001b[K\rremote: Counting objects:  92% (78/84)\u001b[K\rremote: Counting objects:  94% (79/84)\u001b[K\rremote: Counting objects:  95% (80/84)\u001b[K\rremote: Counting objects:  96% (81/84)\u001b[K\rremote: Counting objects:  97% (82/84)\u001b[K\rremote: Counting objects:  98% (83/84)\u001b[K\rremote: Counting objects: 100% (84/84)\u001b[K\rremote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/61)\u001b[K\rremote: Compressing objects:   3% (2/61)\u001b[K\rremote: Compressing objects:   4% (3/61)\u001b[K\rremote: Compressing objects:   6% (4/61)\u001b[K\rremote: Compressing objects:   8% (5/61)\u001b[K\rremote: Compressing objects:   9% (6/61)\u001b[K\rremote: Compressing objects:  11% (7/61)\u001b[K\rremote: Compressing objects:  13% (8/61)\u001b[K\rremote: Compressing objects:  14% (9/61)\u001b[K\rremote: Compressing objects:  16% (10/61)\u001b[K\rremote: Compressing objects:  18% (11/61)\u001b[K\rremote: Compressing objects:  19% (12/61)\u001b[K\rremote: Compressing objects:  21% (13/61)\u001b[K\rremote: Compressing objects:  22% (14/61)\u001b[K\rremote: Compressing objects:  24% (15/61)\u001b[K\rremote: Compressing objects:  26% (16/61)\u001b[K\rremote: Compressing objects:  27% (17/61)\u001b[K\rremote: Compressing objects:  29% (18/61)\u001b[K\rremote: Compressing objects:  31% (19/61)\u001b[K\rremote: Compressing objects:  32% (20/61)\u001b[K\rremote: Compressing objects:  34% (21/61)\u001b[K\rremote: Compressing objects:  36% (22/61)\u001b[K\rremote: Compressing objects:  37% (23/61)\u001b[K\rremote: Compressing objects:  39% (24/61)\u001b[K\rremote: Compressing objects:  40% (25/61)\u001b[K\rremote: Compressing objects:  42% (26/61)\u001b[K\rremote: Compressing objects:  44% (27/61)\u001b[K\rremote: Compressing objects:  45% (28/61)\u001b[K\rremote: Compressing objects:  47% (29/61)\u001b[K\rremote: Compressing objects:  49% (30/61)\u001b[K\rremote: Compressing objects:  50% (31/61)\u001b[K\rremote: Compressing objects:  52% (32/61)\u001b[K\rremote: Compressing objects:  54% (33/61)\u001b[K\rremote: Compressing objects:  55% (34/61)\u001b[K\rremote: Compressing objects:  57% (35/61)\u001b[K\rremote: Compressing objects:  59% (36/61)\u001b[K\rremote: Compressing objects:  60% (37/61)\u001b[K\rremote: Compressing objects:  62% (38/61)\u001b[K\rremote: Compressing objects:  63% (39/61)\u001b[K\rremote: Compressing objects:  65% (40/61)\u001b[K\rremote: Compressing objects:  67% (41/61)\u001b[K\rremote: Compressing objects:  68% (42/61)\u001b[K\rremote: Compressing objects:  70% (43/61)\u001b[K\rremote: Compressing objects:  72% (44/61)\u001b[K\rremote: Compressing objects:  73% (45/61)\u001b[K\rremote: Compressing objects:  75% (46/61)\u001b[K\rremote: Compressing objects:  77% (47/61)\u001b[K\rremote: Compressing objects:  78% (48/61)\u001b[K\rremote: Compressing objects:  80% (49/61)\u001b[K\rremote: Compressing objects:  81% (50/61)\u001b[K\rremote: Compressing objects:  83% (51/61)\u001b[K\rremote: Compressing objects:  85% (52/61)\u001b[K\rremote: Compressing objects:  86% (53/61)\u001b[K\rremote: Compressing objects:  88% (54/61)\u001b[K\rremote: Compressing objects:  90% (55/61)\u001b[K\rremote: Compressing objects:  91% (56/61)\u001b[K\rremote: Compressing objects:  93% (57/61)\u001b[K\rremote: Compressing objects:  95% (58/61)\u001b[K\rremote: Compressing objects:  96% (59/61)\u001b[K\rremote: Compressing objects:  98% (60/61)\u001b[K\rremote: Compressing objects: 100% (61/61)\u001b[K\rremote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "Receiving objects:   0% (1/3768)   \rReceiving objects:   1% (38/3768)   \rReceiving objects:   2% (76/3768)   \rReceiving objects:   3% (114/3768)   \rReceiving objects:   4% (151/3768)   \rReceiving objects:   5% (189/3768)   \rReceiving objects:   6% (227/3768)   \rReceiving objects:   7% (264/3768)   \rReceiving objects:   8% (302/3768)   \rReceiving objects:   9% (340/3768)   \rReceiving objects:  10% (377/3768)   \rReceiving objects:  11% (415/3768)   \rReceiving objects:  12% (453/3768)   \rReceiving objects:  13% (490/3768)   \rReceiving objects:  14% (528/3768)   \rReceiving objects:  15% (566/3768)   \rReceiving objects:  16% (603/3768)   \rReceiving objects:  17% (641/3768)   \rReceiving objects:  18% (679/3768)   \rReceiving objects:  19% (716/3768)   \rReceiving objects:  20% (754/3768)   \rReceiving objects:  21% (792/3768)   \rReceiving objects:  22% (829/3768)   \rReceiving objects:  23% (867/3768)   \rReceiving objects:  24% (905/3768)   \rReceiving objects:  25% (942/3768)   \rReceiving objects:  26% (980/3768)   \rReceiving objects:  27% (1018/3768)   \rReceiving objects:  28% (1056/3768)   \rReceiving objects:  29% (1093/3768)   \rReceiving objects:  30% (1131/3768)   \rReceiving objects:  31% (1169/3768)   \rReceiving objects:  32% (1206/3768)   \rReceiving objects:  33% (1244/3768)   \rReceiving objects:  34% (1282/3768)   \rReceiving objects:  35% (1319/3768)   \rReceiving objects:  36% (1357/3768)   \rReceiving objects:  37% (1395/3768)   \rReceiving objects:  38% (1432/3768)   \rReceiving objects:  39% (1470/3768)   \rReceiving objects:  40% (1508/3768)   \rReceiving objects:  41% (1545/3768)   \rReceiving objects:  42% (1583/3768)   \rReceiving objects:  43% (1621/3768)   \rReceiving objects:  44% (1658/3768)   \rReceiving objects:  45% (1696/3768)   \rReceiving objects:  46% (1734/3768)   \rReceiving objects:  47% (1771/3768)   \rReceiving objects:  48% (1809/3768)   \rReceiving objects:  49% (1847/3768)   \rReceiving objects:  50% (1884/3768)   \rReceiving objects:  51% (1922/3768)   \rReceiving objects:  52% (1960/3768)   \rReceiving objects:  53% (1998/3768)   \rReceiving objects:  54% (2035/3768)   \rReceiving objects:  55% (2073/3768)   \rReceiving objects:  56% (2111/3768)   \rReceiving objects:  57% (2148/3768)   \rReceiving objects:  58% (2186/3768)   \rReceiving objects:  59% (2224/3768)   \rReceiving objects:  60% (2261/3768)   \rReceiving objects:  61% (2299/3768)   \rReceiving objects:  62% (2337/3768)   \rReceiving objects:  63% (2374/3768)   \rReceiving objects:  64% (2412/3768)   \rReceiving objects:  65% (2450/3768)   \rReceiving objects:  66% (2487/3768)   \rReceiving objects:  67% (2525/3768)   \rReceiving objects:  68% (2563/3768)   \rReceiving objects:  69% (2600/3768)   \rReceiving objects:  70% (2638/3768)   \rReceiving objects:  71% (2676/3768)   \rReceiving objects:  72% (2713/3768)   \rReceiving objects:  73% (2751/3768)   \rReceiving objects:  74% (2789/3768)   \rReceiving objects:  75% (2826/3768)   \rReceiving objects:  76% (2864/3768)   \rReceiving objects:  77% (2902/3768)   \rReceiving objects:  78% (2940/3768)   \rReceiving objects:  79% (2977/3768)   \rReceiving objects:  80% (3015/3768)   \rReceiving objects:  81% (3053/3768)   \rReceiving objects:  82% (3090/3768)   \rReceiving objects:  83% (3128/3768)   \rReceiving objects:  84% (3166/3768)   \rReceiving objects:  85% (3203/3768)   \rReceiving objects:  86% (3241/3768)   \rReceiving objects:  87% (3279/3768)   \rReceiving objects:  88% (3316/3768)   \rReceiving objects:  89% (3354/3768)   \rReceiving objects:  90% (3392/3768)   \rReceiving objects:  91% (3429/3768)   \rReceiving objects:  92% (3467/3768)   \rReceiving objects:  93% (3505/3768)   \rReceiving objects:  94% (3542/3768)   \rReceiving objects:  95% (3580/3768)   \rReceiving objects:  96% (3618/3768)   \rReceiving objects:  97% (3655/3768)   \rReceiving objects:  98% (3693/3768)   \rremote: Total 3768 (delta 35), reused 46 (delta 15), pack-reused 3684\u001b[K\n",
            "Receiving objects:  99% (3731/3768)   \rReceiving objects: 100% (3768/3768)   \rReceiving objects: 100% (3768/3768), 8.20 MiB | 33.19 MiB/s, done.\n",
            "Resolving deltas:   0% (0/2354)   \rResolving deltas:   1% (29/2354)   \rResolving deltas:   2% (54/2354)   \rResolving deltas:   3% (74/2354)   \rResolving deltas:   4% (97/2354)   \rResolving deltas:   5% (121/2354)   \rResolving deltas:   6% (142/2354)   \rResolving deltas:   7% (166/2354)   \rResolving deltas:   8% (190/2354)   \rResolving deltas:  10% (239/2354)   \rResolving deltas:  11% (272/2354)   \rResolving deltas:  12% (288/2354)   \rResolving deltas:  13% (307/2354)   \rResolving deltas:  14% (331/2354)   \rResolving deltas:  15% (365/2354)   \rResolving deltas:  16% (378/2354)   \rResolving deltas:  17% (401/2354)   \rResolving deltas:  18% (439/2354)   \rResolving deltas:  19% (448/2354)   \rResolving deltas:  20% (472/2354)   \rResolving deltas:  23% (558/2354)   \rResolving deltas:  24% (567/2354)   \rResolving deltas:  25% (589/2354)   \rResolving deltas:  26% (614/2354)   \rResolving deltas:  27% (641/2354)   \rResolving deltas:  28% (663/2354)   \rResolving deltas:  29% (686/2354)   \rResolving deltas:  30% (707/2354)   \rResolving deltas:  31% (735/2354)   \rResolving deltas:  32% (757/2354)   \rResolving deltas:  33% (780/2354)   \rResolving deltas:  35% (847/2354)   \rResolving deltas:  36% (851/2354)   \rResolving deltas:  37% (887/2354)   \rResolving deltas:  39% (920/2354)   \rResolving deltas:  43% (1020/2354)   \rResolving deltas:  46% (1087/2354)   \rResolving deltas:  49% (1173/2354)   \rResolving deltas:  50% (1189/2354)   \rResolving deltas:  51% (1202/2354)   \rResolving deltas:  52% (1226/2354)   \rResolving deltas:  53% (1261/2354)   \rResolving deltas:  55% (1301/2354)   \rResolving deltas:  56% (1323/2354)   \rResolving deltas:  60% (1429/2354)   \rResolving deltas:  62% (1469/2354)   \rResolving deltas:  63% (1487/2354)   \rResolving deltas:  64% (1509/2354)   \rResolving deltas:  66% (1558/2354)   \rResolving deltas:  67% (1581/2354)   \rResolving deltas:  68% (1604/2354)   \rResolving deltas:  69% (1639/2354)   \rResolving deltas:  70% (1651/2354)   \rResolving deltas:  71% (1690/2354)   \rResolving deltas:  72% (1695/2354)   \rResolving deltas:  74% (1749/2354)   \rResolving deltas:  78% (1856/2354)   \rResolving deltas:  81% (1910/2354)   \rResolving deltas:  82% (1931/2354)   \rResolving deltas:  83% (1955/2354)   \rResolving deltas:  84% (1980/2354)   \rResolving deltas:  85% (2003/2354)   \rResolving deltas:  86% (2028/2354)   \rResolving deltas:  87% (2052/2354)   \rResolving deltas:  88% (2076/2354)   \rResolving deltas:  89% (2105/2354)   \rResolving deltas:  90% (2140/2354)   \rResolving deltas:  91% (2152/2354)   \rResolving deltas:  92% (2172/2354)   \rResolving deltas:  93% (2209/2354)   \rResolving deltas:  94% (2224/2354)   \rResolving deltas:  96% (2277/2354)   \rResolving deltas:  97% (2285/2354)   \rResolving deltas:  98% (2310/2354)   \rResolving deltas:  99% (2332/2354)   \rResolving deltas: 100% (2354/2354)   \rResolving deltas: 100% (2354/2354), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrzdvhfIbfTm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "649f6329-d3fb-44aa-aa06-608aeaee4baf"
      },
      "source": [
        "cd fastText/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fastText\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3_GOupEbhOX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "df6530cd-1dc2-4a84-ea7b-9219808bc572"
      },
      "source": [
        "!pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/fastText\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (46.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (1.18.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2875528 sha256=92fff9279bd5047097a95226c782701e70564db2c1314fed17d11ac8be0e67ba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zjghjcqi/wheels/a1/9f/52/696ce6c5c46325e840c76614ee5051458c0df10306987e7443\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nwh7TLl62SX"
      },
      "source": [
        "# Load and combine eng-hindi dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ryrczE4fhQw"
      },
      "source": [
        "def load_embedding_dict(embedding_path, embedding_size, embedding_format):\n",
        "    \"\"\"\n",
        "    Load emb dict from file, or load pre trained binary fasttext model.\n",
        "    Args:\n",
        "        embedding_path: path to the vec file, or binary model\n",
        "        embedding_size: int, embedding_size\n",
        "        embedding_format: 'bin' or 'vec'\n",
        "\n",
        "    Returns: Embeddings dict, or fasttext pre trained model\n",
        "\n",
        "    \"\"\"\n",
        "    print(\"Loading word embeddings from {}...\".format(embedding_path))\n",
        "    count = 0\n",
        "    count_t = 0\n",
        "    if embedding_format == 'vec':\n",
        "        default_embedding = np.zeros(embedding_size)\n",
        "        embedding_dict = collections.defaultdict(lambda: default_embedding)\n",
        "        skip_first = embedding_format == \"vec\"\n",
        "        with open(embedding_path) as f:\n",
        "            \n",
        "            for i, line in enumerate(f.readlines()):\n",
        "                if skip_first and i == 0:\n",
        "                    continue\n",
        "                splits = line.split()\n",
        "                # print(len(splits),i)\n",
        "                if (len(splits) == embedding_size + 1):\n",
        "                    count_t = count_t+1\n",
        "                    word = splits[0]\n",
        "                    embedding = np.array([float(s) for s in splits[1:]])\n",
        "                    embedding_dict[word] = embedding\n",
        "                else:\n",
        "                    count = count+1\n",
        "    elif embedding_format == 'bin':\n",
        "        embedding_dict = fasttext.load_model(embedding_path)\n",
        "    else:\n",
        "        raise ValueError('Not supported embeddings format {}'.format(embedding_format))\n",
        "    print(\"Done loading word embeddings.\")\n",
        "    print(count_t,count)\n",
        "    return embedding_dict "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJrmOZKTge3n"
      },
      "source": [
        "import collections\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFyvJ7E5gIM8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4f270e1f-8359-402d-9e32-164a9b985e93"
      },
      "source": [
        "hi_dictionary = load_embedding_dict(\"/content/gdrive/My Drive/Phd_implementation/minor_project2/wiki.hi.align.vec\", embedding_size = 300, embedding_format = \"vec\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word embeddings from /content/gdrive/My Drive/Phd_implementation/minor_project2/wiki.hi.align.vec...\n",
            "Done loading word embeddings.\n",
            "157993 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zi9tQkbgbUa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f8801497-d855-4a3d-f25d-e7c253649a4d"
      },
      "source": [
        "en_dictionary = load_embedding_dict(\"/content/gdrive/My Drive/Phd_implementation/minor_project2/wiki.en.align.vec\", embedding_size = 300, embedding_format = \"vec\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word embeddings from /content/gdrive/My Drive/Phd_implementation/minor_project2/wiki.en.align.vec...\n",
            "Done loading word embeddings.\n",
            "2519178 192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYl9g6EWl6xP"
      },
      "source": [
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.en.align.vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waywlnD4mBx9"
      },
      "source": [
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.hi.align.vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNZnrQ3ondFs"
      },
      "source": [
        "# !cp /content/fastText/wiki.en.align.vec \"/content/gdrive/My Drive/minor_project2/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO6EI4nfoj9P"
      },
      "source": [
        "# !cp /content/fastText/wiki.hi.align.vec \"/content/gdrive/My Drive/minor_project2/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdF06eaNsJrW"
      },
      "source": [
        "z = {**hi_dictionary, **en_dictionary}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZaJEPw9ukZ3"
      },
      "source": [
        "# import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5PFGYFSsuYi"
      },
      "source": [
        "# with open('/content/gdrive/My Drive/minor_project2/en_hi_dict.txt', 'wb') as handle:\n",
        "#   pickle.dump(z, handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA6pJo2o69VM"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwJkF-HTBq2r"
      },
      "source": [
        "## Hindi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo4cLNAlujbZ"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec7r5hiM3JBu"
      },
      "source": [
        "\n",
        "data = pd.read_csv('/content/gdrive/My Drive/Phd_implementation/Location_multilingual/csv files/label_Partho - label_Partho.csv')\n",
        "data2 = pd.read_csv('/content/gdrive/My Drive/Phd_implementation/Location_multilingual/csv files/label_Adarsh - label_Adarsh.csv')\n",
        "data3 = pd.read_csv('/content/gdrive/My Drive/Phd_implementation/Location_multilingual/csv files/label_Keshav - label_Keshav.csv')\n",
        "data4 = pd.read_csv('/content/gdrive/My Drive/Phd_implementation/Location_multilingual/csv files/label_Gaurav - label_Gaurav.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJIvDHJS3LAh"
      },
      "source": [
        "df1 = data.dropna(subset=['location1'])\n",
        "df2 = data2.dropna(subset=['location1'])\n",
        "df3 = data3.dropna(subset=['location1'])\n",
        "df4 = data4.dropna(subset=['location1'])\n",
        "combined_df = pd.concat([df1, df2, df3, df4], sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq68VVKu3M4K"
      },
      "source": [
        "combined_df = combined_df[['id','text','location1','location2','location3','location4','location5']]\n",
        "\n",
        "combined_df\n",
        "\n",
        "tweet = list(combined_df['text'])\n",
        "location1 = list(combined_df['location1'])\n",
        "location2 = list(combined_df['location2'])\n",
        "location3 = list(combined_df['location3'])\n",
        "location4 = list(combined_df['location4'])\n",
        "location5 = list(combined_df['location5'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m9-81edBw_U"
      },
      "source": [
        "## English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4YsYc_v3PGg"
      },
      "source": [
        "data_eng = pd.read_csv(\"/content/gdrive/My Drive/Phd_implementation/Location_multilingual/csv files/Eq_Lab3000_updated.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGkdpAT26OJA"
      },
      "source": [
        "data_eng = data_eng[['tweets','labels']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm4Xj5OnFYQU"
      },
      "source": [
        "data_eng = data_eng.dropna(subset=['labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_xlQLcD6Pfa"
      },
      "source": [
        "data_eng = data_eng[data_eng['labels'] != '0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7hiBIpyFqhg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "d764f40b-5c47-4a4f-f9be-0c55cc956297"
      },
      "source": [
        "data_eng"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>earthquake m km ssw of gambell alaska mins ago...</td>\n",
              "      <td>6 7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rt tremblement de terre mag km de jiangzikeng ...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rt and on the th anniversary of the earthquake...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>rt and now we re reaching the present moment i...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>rt massive magnitude earthquake hits taipei</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2994</th>\n",
              "      <td>rt earthquake m alaska peninsula mins ago jan ...</td>\n",
              "      <td>4 5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>annelizebester rt laco f twenty four years ago...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>earthquake in san francisco bitcoin s dear god...</td>\n",
              "      <td>3 4 9 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>here s what the office looked like after the n...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3000</th>\n",
              "      <td>not to mention the haiti earthquake that kille...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1903 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 tweets    labels\n",
              "1     earthquake m km ssw of gambell alaska mins ago...       6 7\n",
              "3     rt tremblement de terre mag km de jiangzikeng ...         8\n",
              "4     rt and on the th anniversary of the earthquake...        11\n",
              "5     rt and now we re reaching the present moment i...        16\n",
              "8           rt massive magnitude earthquake hits taipei         6\n",
              "...                                                 ...       ...\n",
              "2994  rt earthquake m alaska peninsula mins ago jan ...       4 5\n",
              "2996  annelizebester rt laco f twenty four years ago...        14\n",
              "2997  earthquake in san francisco bitcoin s dear god...  3 4 9 10\n",
              "2999  here s what the office looked like after the n...        10\n",
              "3000  not to mention the haiti earthquake that kille...         5\n",
              "\n",
              "[1903 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXcwzviiC-Pq"
      },
      "source": [
        "tweet_eng = list(data_eng['tweets'])\n",
        "labels = list(data_eng['labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiTg0h1dDts4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb107826-827d-4149-da82-d036de421f67"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['6 7',\n",
              " '8',\n",
              " '11',\n",
              " '16',\n",
              " '6',\n",
              " '16',\n",
              " '4 5',\n",
              " '32',\n",
              " '8 9',\n",
              " '7 8',\n",
              " '23',\n",
              " '6 7',\n",
              " '2 3',\n",
              " ' 8 13',\n",
              " '12 13',\n",
              " '9',\n",
              " '9',\n",
              " '7',\n",
              " '5',\n",
              " '5',\n",
              " '9',\n",
              " '26',\n",
              " '14',\n",
              " '7 19',\n",
              " '26',\n",
              " '9',\n",
              " '7',\n",
              " '17 18 19 20 21 22 23 24',\n",
              " '6 7 8',\n",
              " '9',\n",
              " '14 41',\n",
              " '4 5 9',\n",
              " '8 9 10 11',\n",
              " '18',\n",
              " '10 11 12 13',\n",
              " '13 23',\n",
              " '11 12',\n",
              " '9 10 11',\n",
              " '4 5',\n",
              " '9 10 17',\n",
              " '8',\n",
              " '4 5 6',\n",
              " '1',\n",
              " '15 16 17 22 26',\n",
              " '5',\n",
              " '30 31',\n",
              " '4',\n",
              " '8',\n",
              " '7 8',\n",
              " '9 10 11',\n",
              " '8 9 10',\n",
              " '20',\n",
              " '4 5 9',\n",
              " '9 10',\n",
              " '9',\n",
              " '6 7 8 12',\n",
              " '9',\n",
              " '5 6',\n",
              " '13',\n",
              " '5 8',\n",
              " '2 14',\n",
              " '7',\n",
              " '5 6',\n",
              " '7 8 9',\n",
              " '2 10',\n",
              " '5 6',\n",
              " '5',\n",
              " '2 3 4 5',\n",
              " '8 9 10',\n",
              " '9',\n",
              " '6',\n",
              " '1 2',\n",
              " '10',\n",
              " '14',\n",
              " '8 9',\n",
              " '8',\n",
              " '9 10',\n",
              " '9 10 11 12',\n",
              " '4',\n",
              " '10 13 17 37',\n",
              " '10',\n",
              " '8',\n",
              " '6 7 11',\n",
              " '2 3',\n",
              " '4',\n",
              " '1',\n",
              " '4 5 6 10',\n",
              " '9 10',\n",
              " '11 12',\n",
              " '11 12',\n",
              " '7',\n",
              " '6 7',\n",
              " '16',\n",
              " '5',\n",
              " '3',\n",
              " '7 8',\n",
              " '1 2 3 4 6',\n",
              " '4 8',\n",
              " '13',\n",
              " '7 8 9 10',\n",
              " '5',\n",
              " '1 2 3 4 5 7',\n",
              " '5  31',\n",
              " ' 6 7',\n",
              " '3 4',\n",
              " '5 7 8',\n",
              " '4',\n",
              " '5',\n",
              " '4',\n",
              " '16',\n",
              " '6',\n",
              " '9  11 12  15',\n",
              " '7 8',\n",
              " '7',\n",
              " '14',\n",
              " '10',\n",
              " '6 7 11',\n",
              " '17',\n",
              " '9',\n",
              " '10 11',\n",
              " '15',\n",
              " '5 6 7',\n",
              " '10',\n",
              " '5',\n",
              " '6 7',\n",
              " '3 4',\n",
              " '6 7',\n",
              " '9 10',\n",
              " '9 10',\n",
              " '24',\n",
              " '6 7',\n",
              " '9 11',\n",
              " '3 4 5',\n",
              " '2 8',\n",
              " '1 2',\n",
              " '1 2',\n",
              " '3 4 5 6 7',\n",
              " '5 6 7 8 10',\n",
              " '3 4',\n",
              " '13 14',\n",
              " '14 15',\n",
              " '4 8',\n",
              " '1 2 31 32',\n",
              " '14',\n",
              " '5',\n",
              " '4',\n",
              " '5 6 7 8 ',\n",
              " '2',\n",
              " '           8 9 10 11',\n",
              " '3',\n",
              " ' 4 5 6 7 8 11',\n",
              " '10 11',\n",
              " '5 6',\n",
              " '5',\n",
              " '9 10',\n",
              " '8 9',\n",
              " '13',\n",
              " '20',\n",
              " '5 6 7',\n",
              " '9',\n",
              " '1 2 3',\n",
              " '7 8',\n",
              " '8 9',\n",
              " '1',\n",
              " '10 11',\n",
              " '4  7 8',\n",
              " '6 7 8 9',\n",
              " '4',\n",
              " '6 7',\n",
              " '6 7',\n",
              " '6',\n",
              " '7',\n",
              " '14',\n",
              " '15',\n",
              " '1 3 4 5',\n",
              " '12 13',\n",
              " '8 9 10',\n",
              " '7 8 9',\n",
              " '4 5',\n",
              " '3',\n",
              " '7 8',\n",
              " '9 10',\n",
              " '5 6 7',\n",
              " '4 5 9',\n",
              " '3 5',\n",
              " ' 8 9 10',\n",
              " '10',\n",
              " '3',\n",
              " '3 4 7 9 11',\n",
              " '6',\n",
              " '4 5 6 7 8  12',\n",
              " '5 6 10',\n",
              " '1',\n",
              " ' 8 9 10',\n",
              " '9 10',\n",
              " '2 3',\n",
              " '6 7',\n",
              " '5 6 7 8',\n",
              " '3',\n",
              " '5 6 7',\n",
              " '1',\n",
              " ' 3 9 10',\n",
              " '9',\n",
              " '8',\n",
              " '4',\n",
              " '6 7 10',\n",
              " '6',\n",
              " '9 10',\n",
              " ' 5 17  25',\n",
              " '4',\n",
              " '5 6 7 8',\n",
              " '5 11',\n",
              " '1',\n",
              " '43',\n",
              " '8 9',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '3 4',\n",
              " '7 8 9 10 11',\n",
              " '5',\n",
              " '9 10',\n",
              " '5 6 7 8',\n",
              " '13',\n",
              " '7  9  15 17',\n",
              " '3',\n",
              " '14',\n",
              " '7 8 9',\n",
              " '10',\n",
              " '4 5 6 7  11',\n",
              " '21 22 32',\n",
              " '5 6 7',\n",
              " '4',\n",
              " '6 7',\n",
              " '6',\n",
              " '5 6 7 11',\n",
              " '4 23',\n",
              " '17',\n",
              " '6 7 8',\n",
              " '8 9 10',\n",
              " '3 4 6',\n",
              " '6',\n",
              " '4 5 6 7 8',\n",
              " '5',\n",
              " '6 7',\n",
              " '10 11',\n",
              " '1 2',\n",
              " '6 7 8 12',\n",
              " '6 7',\n",
              " '9',\n",
              " '7  13 14 15',\n",
              " '10',\n",
              " '8',\n",
              " '9 17 19',\n",
              " '8 9 10 11',\n",
              " '7 8 9',\n",
              " '9',\n",
              " '1',\n",
              " '1 5',\n",
              " '7 8 13 14 34 35 36 37',\n",
              " '5',\n",
              " ' 8 9',\n",
              " '2 3',\n",
              " '7 8',\n",
              " '5 6 7 8',\n",
              " '6 7',\n",
              " '1 2 3 4',\n",
              " '     9 10 11 12 13',\n",
              " '6 7 8 9 10',\n",
              " '8 34',\n",
              " '8',\n",
              " '6 7 11',\n",
              " '6 7 8 12',\n",
              " '10 12',\n",
              " '8 23',\n",
              " '29',\n",
              " '6 7',\n",
              " '6 7',\n",
              " '5',\n",
              " '1 8',\n",
              " '6',\n",
              " '3 4',\n",
              " '16 18',\n",
              " '6',\n",
              " '15',\n",
              " '6',\n",
              " '21 46',\n",
              " '7',\n",
              " '1 4 5 6 7 10',\n",
              " '4 5 6 7  14 15 16 17',\n",
              " '4 5 9',\n",
              " '7 8 9',\n",
              " '4',\n",
              " '5 9',\n",
              " '11 12 28',\n",
              " '6 7  11',\n",
              " '11',\n",
              " '15',\n",
              " '7 10 20 24',\n",
              " '6',\n",
              " '3',\n",
              " '4 7 34  40',\n",
              " '7',\n",
              " '10',\n",
              " '16',\n",
              " '9 10 11',\n",
              " '6',\n",
              " '2',\n",
              " '9 10 11 12 13 14',\n",
              " '4',\n",
              " '7 8 9 10',\n",
              " '8 15',\n",
              " '8',\n",
              " '7 9',\n",
              " '4',\n",
              " '7 8',\n",
              " '10',\n",
              " '6 11',\n",
              " '7 8',\n",
              " '6 7',\n",
              " '9 10',\n",
              " '8 9 10',\n",
              " '5 6',\n",
              " '9 10 11',\n",
              " '6 7 8',\n",
              " '11',\n",
              " '6 7',\n",
              " '7 8 9',\n",
              " '10',\n",
              " '7 8 10',\n",
              " '1',\n",
              " '8',\n",
              " '9',\n",
              " '16',\n",
              " '10',\n",
              " '6 7',\n",
              " '4 5 6 7',\n",
              " '28',\n",
              " '12',\n",
              " '16',\n",
              " '10 19',\n",
              " '8',\n",
              " '5',\n",
              " '9',\n",
              " '1 7',\n",
              " '8',\n",
              " '1 6',\n",
              " '8',\n",
              " '5 6',\n",
              " '16',\n",
              " '9',\n",
              " '3',\n",
              " '2',\n",
              " '1',\n",
              " '9 10 11',\n",
              " '10',\n",
              " '10 11 12 13',\n",
              " '5',\n",
              " '13 14 15',\n",
              " '12',\n",
              " '6 10',\n",
              " '2',\n",
              " '6 7 8',\n",
              " '5',\n",
              " '6',\n",
              " '5 6',\n",
              " '8 9',\n",
              " '11',\n",
              " '5',\n",
              " '3 8',\n",
              " '11',\n",
              " '6 7',\n",
              " '10',\n",
              " '8',\n",
              " '5',\n",
              " '7 8',\n",
              " '14',\n",
              " '6 7',\n",
              " '6',\n",
              " '3',\n",
              " '8',\n",
              " '3',\n",
              " '9',\n",
              " '7 8',\n",
              " '8',\n",
              " '14 15 17 18',\n",
              " '8 23',\n",
              " '10 11',\n",
              " '4',\n",
              " '4 28',\n",
              " '8',\n",
              " '3 4',\n",
              " '7',\n",
              " '6 7 8',\n",
              " '32',\n",
              " '21',\n",
              " '8',\n",
              " '8',\n",
              " '9 10 11',\n",
              " '8 9',\n",
              " '10',\n",
              " '7 8',\n",
              " '11',\n",
              " '6',\n",
              " '28',\n",
              " '7',\n",
              " '8 10',\n",
              " '5 6 7',\n",
              " '17',\n",
              " '3',\n",
              " '3 5',\n",
              " '4 5',\n",
              " '19',\n",
              " '2 11 14',\n",
              " '5 14',\n",
              " '8 9',\n",
              " '4 5',\n",
              " '12',\n",
              " '3 4',\n",
              " '13',\n",
              " '7 8',\n",
              " '4',\n",
              " '8 9',\n",
              " '5 6',\n",
              " '12',\n",
              " '6',\n",
              " '11 12',\n",
              " '10 11',\n",
              " '14',\n",
              " '7 8',\n",
              " '8 9',\n",
              " '9',\n",
              " '13',\n",
              " '10 11 30 31',\n",
              " '7',\n",
              " '1 2',\n",
              " '2 3',\n",
              " '8',\n",
              " '6',\n",
              " '7',\n",
              " '18',\n",
              " '4 7',\n",
              " '8',\n",
              " '3 4 5',\n",
              " '3',\n",
              " '25',\n",
              " '5',\n",
              " '9',\n",
              " '4',\n",
              " '6',\n",
              " '2 3 7 8',\n",
              " '9',\n",
              " '9',\n",
              " '6 7 8',\n",
              " '7',\n",
              " '3 6',\n",
              " '6 11',\n",
              " '7 8',\n",
              " '6 7 8',\n",
              " '6 7 8 9',\n",
              " '4',\n",
              " '8',\n",
              " '9 10',\n",
              " '8',\n",
              " '10',\n",
              " '7 8 9',\n",
              " '7',\n",
              " '3',\n",
              " '4',\n",
              " '17',\n",
              " '37 38',\n",
              " '7 8 9',\n",
              " '17',\n",
              " '2 3',\n",
              " '16',\n",
              " '8',\n",
              " '4',\n",
              " '3 4 6',\n",
              " '20',\n",
              " '9',\n",
              " '10 11',\n",
              " '2 3 4',\n",
              " '17',\n",
              " '7 8 10',\n",
              " '7 8 9',\n",
              " '20',\n",
              " '8 9',\n",
              " '11',\n",
              " '9 10',\n",
              " '4 5 9',\n",
              " '3',\n",
              " '4',\n",
              " '6 7 8 9',\n",
              " '6 11',\n",
              " '5 6 8',\n",
              " '9 23',\n",
              " '2',\n",
              " '10',\n",
              " '3 4 5',\n",
              " '5 6 7 12 13 14',\n",
              " '14',\n",
              " '6 7 8',\n",
              " '3 4 5',\n",
              " '4',\n",
              " '10 12',\n",
              " '11 12',\n",
              " '6 9',\n",
              " '1 2',\n",
              " '10',\n",
              " '7 8 9',\n",
              " '6 7 8 9',\n",
              " '5 6 7',\n",
              " '5',\n",
              " '7',\n",
              " '9 10',\n",
              " '23',\n",
              " '8',\n",
              " '6 7',\n",
              " '8 18',\n",
              " '7 52',\n",
              " '2 3 12 13 26',\n",
              " '5',\n",
              " '8',\n",
              " '2 3',\n",
              " '3',\n",
              " '8 9',\n",
              " '2',\n",
              " '2',\n",
              " '7',\n",
              " '7',\n",
              " '1',\n",
              " '3 4',\n",
              " '5 6',\n",
              " '4',\n",
              " '4 5',\n",
              " '7 8',\n",
              " '15',\n",
              " '1',\n",
              " '4 5 6 7 11',\n",
              " '3 4',\n",
              " '6 7 8',\n",
              " '6 7',\n",
              " '3',\n",
              " '10',\n",
              " '31',\n",
              " '5 6 7 8',\n",
              " '5',\n",
              " '7 8',\n",
              " '4 5 6',\n",
              " '4',\n",
              " '9 10',\n",
              " '5',\n",
              " '12',\n",
              " '5 6',\n",
              " '5',\n",
              " '7 8 9',\n",
              " '4',\n",
              " '1 14',\n",
              " '5',\n",
              " '9 10 11',\n",
              " '6 7',\n",
              " '4 8 9',\n",
              " '8',\n",
              " '4 5',\n",
              " '6 7',\n",
              " '8',\n",
              " '9 10',\n",
              " '7 8',\n",
              " '8 9',\n",
              " '5',\n",
              " '10',\n",
              " '5',\n",
              " '7',\n",
              " '3 4 5',\n",
              " '7',\n",
              " '8 9 10',\n",
              " '7 8',\n",
              " '7',\n",
              " '3 4',\n",
              " '7 8 9',\n",
              " '4',\n",
              " '1',\n",
              " '3',\n",
              " '4 5 6',\n",
              " '9 10',\n",
              " '9 10 12',\n",
              " '4 5',\n",
              " '6 7',\n",
              " '6 9 10',\n",
              " '5 6 7',\n",
              " '3',\n",
              " '7',\n",
              " '5',\n",
              " '6',\n",
              " '11 12',\n",
              " '6 8 9',\n",
              " '8 9',\n",
              " '10',\n",
              " '10 13',\n",
              " '1 2 8 9 14 15 16 22 27 29 30',\n",
              " '6 20',\n",
              " '1 11',\n",
              " '4',\n",
              " '6 7',\n",
              " '11 19 28 29 30',\n",
              " '8 9 10',\n",
              " '6 7 8 9',\n",
              " '5',\n",
              " '1 6 7',\n",
              " '29',\n",
              " '1 13 14 15',\n",
              " '6 7 8',\n",
              " '6',\n",
              " '6 7',\n",
              " '1',\n",
              " '1 11',\n",
              " '8',\n",
              " '21 29 31 32 33 34',\n",
              " '3',\n",
              " '3',\n",
              " '4 7',\n",
              " '14',\n",
              " '26',\n",
              " '10',\n",
              " '6 7 11',\n",
              " '5 6 7 12 13 14',\n",
              " '4',\n",
              " '7 11 12',\n",
              " '7',\n",
              " '8 9 10 11',\n",
              " '12',\n",
              " '2',\n",
              " '7',\n",
              " '9 10',\n",
              " '8',\n",
              " '8 9',\n",
              " '6 7 8',\n",
              " '7 8',\n",
              " '6',\n",
              " '1',\n",
              " '19',\n",
              " '9 10 11',\n",
              " '6 7',\n",
              " '1',\n",
              " '1 2 3',\n",
              " '6 7',\n",
              " '6 7 8',\n",
              " '2 3',\n",
              " '5',\n",
              " '6',\n",
              " '5 11 12 16',\n",
              " '6 7 8',\n",
              " '4 5 6 10 11',\n",
              " '48',\n",
              " '20',\n",
              " '2',\n",
              " '7 8',\n",
              " '7 8 9',\n",
              " '10',\n",
              " '13 14',\n",
              " '14 18',\n",
              " '3 4 11',\n",
              " '8 9',\n",
              " '10',\n",
              " '8',\n",
              " '8',\n",
              " '6 7 11',\n",
              " '2',\n",
              " '6 7 8 9',\n",
              " '8',\n",
              " '5 6',\n",
              " '4 5 6 7',\n",
              " '8 9 10 11 12 13 14',\n",
              " '15 24',\n",
              " '5 6 7 8',\n",
              " '7 8',\n",
              " '8',\n",
              " '1',\n",
              " '7',\n",
              " '30',\n",
              " '31',\n",
              " '1',\n",
              " '2',\n",
              " '4 5 8 9 13',\n",
              " '14 15',\n",
              " '1 2 3 5 6 7',\n",
              " '6 7 8',\n",
              " '7',\n",
              " '4 7 8 9',\n",
              " '8 9',\n",
              " '15 18',\n",
              " '4',\n",
              " '8 9 10 11',\n",
              " '10',\n",
              " '4 5 6 10',\n",
              " '14',\n",
              " '8 9',\n",
              " '10 34',\n",
              " '11 12',\n",
              " '1',\n",
              " '5',\n",
              " '24',\n",
              " '5 8 11 13',\n",
              " '4',\n",
              " '11 29 36',\n",
              " '10',\n",
              " '4 5 6 8',\n",
              " '15',\n",
              " '3',\n",
              " '24 32',\n",
              " '10 11',\n",
              " '7',\n",
              " '11',\n",
              " '11 23',\n",
              " '7 8 9',\n",
              " '1 2',\n",
              " '14 15 16 17',\n",
              " '8 9 10 11',\n",
              " '6 7 11',\n",
              " '5',\n",
              " '6 7',\n",
              " '4',\n",
              " '5 6 7 8',\n",
              " '14',\n",
              " '6 7 8 9',\n",
              " '6 7',\n",
              " '8 9 10',\n",
              " '6 17 18 19 28',\n",
              " '6 7',\n",
              " '8',\n",
              " '10 11 12 13',\n",
              " '7 8  9',\n",
              " '11',\n",
              " '1 2',\n",
              " '21',\n",
              " '1 3 23 24 25 26 27 30',\n",
              " '39',\n",
              " '5 6 7',\n",
              " '7',\n",
              " '6 7',\n",
              " '7',\n",
              " '8 9',\n",
              " '14',\n",
              " '9',\n",
              " '8 9 10 12 13',\n",
              " '7',\n",
              " '9 17',\n",
              " '6',\n",
              " '5 6 7 8 9 10',\n",
              " '1',\n",
              " '15',\n",
              " '3 4 5',\n",
              " '12',\n",
              " '6 7 8',\n",
              " '5 6',\n",
              " '1 6',\n",
              " '14 26 37',\n",
              " '1',\n",
              " '9 18 21',\n",
              " '6 7 8 9 10',\n",
              " '5',\n",
              " '6',\n",
              " '3 4',\n",
              " '7',\n",
              " '13',\n",
              " '2 3 4 5',\n",
              " '7 8 9 10 16 17 18 19',\n",
              " '2 3 7 8',\n",
              " '10',\n",
              " '4',\n",
              " '5 6 7 8 ',\n",
              " '10',\n",
              " '7 8 9',\n",
              " '1',\n",
              " '6',\n",
              " '12',\n",
              " '10 11',\n",
              " '2 7',\n",
              " '6',\n",
              " '4 5',\n",
              " '3 4',\n",
              " '19',\n",
              " '9 10',\n",
              " '4',\n",
              " '6',\n",
              " '15',\n",
              " '13',\n",
              " '27',\n",
              " '3 4',\n",
              " '9',\n",
              " '4 5',\n",
              " '8 10',\n",
              " '6 7 8 12',\n",
              " '2 3 4',\n",
              " '6',\n",
              " '1',\n",
              " '3 4 5 9 10  11 17 18 19 32 35',\n",
              " '6 7 11',\n",
              " '7 8',\n",
              " '5 6 33',\n",
              " '6 7 13 14',\n",
              " '1',\n",
              " '3 4',\n",
              " '11 12',\n",
              " '10 11',\n",
              " '1',\n",
              " '3 7 16 28',\n",
              " '8 9',\n",
              " '8',\n",
              " '8 9 10',\n",
              " '7 8 9 10',\n",
              " '5 6 8',\n",
              " '11 40',\n",
              " '5',\n",
              " '2 4 8 10',\n",
              " '3',\n",
              " '5',\n",
              " '11 12',\n",
              " '9 10 11',\n",
              " '15 16',\n",
              " '10',\n",
              " '9 10',\n",
              " '4',\n",
              " '3 6 7 10 19 21 22 24 ',\n",
              " '20 21 22',\n",
              " '3 13 14 34 35',\n",
              " '3 15',\n",
              " '8 9 10 11 12',\n",
              " '9 10',\n",
              " '20',\n",
              " '5 6 19 35',\n",
              " '9 10',\n",
              " '7 8 9',\n",
              " '17',\n",
              " '21 22',\n",
              " '8 9',\n",
              " '6',\n",
              " '2 3 7 8',\n",
              " '1',\n",
              " '5',\n",
              " '11 12',\n",
              " '40',\n",
              " '14',\n",
              " '29',\n",
              " '5 6 7',\n",
              " '7 8 9 13 14',\n",
              " '5',\n",
              " '13',\n",
              " '3 4 12 13',\n",
              " '12',\n",
              " '1',\n",
              " '11 12',\n",
              " '6 7 8',\n",
              " '8 9',\n",
              " '7 8 9',\n",
              " '9 14',\n",
              " '6 7 8 9',\n",
              " '7 8 9',\n",
              " '9 10 11',\n",
              " '13',\n",
              " '2',\n",
              " '2',\n",
              " '19',\n",
              " '9',\n",
              " '10',\n",
              " '2 3',\n",
              " '7 8',\n",
              " '5 10 18',\n",
              " '9 10 11 12',\n",
              " '5 6 7',\n",
              " '10',\n",
              " '10 11',\n",
              " '5 6 7',\n",
              " '9 10 11',\n",
              " '7 8',\n",
              " '10 22',\n",
              " '8 9',\n",
              " '2 3 4 5',\n",
              " '5 31 34 46',\n",
              " '7 8 9',\n",
              " '9 10',\n",
              " '4 5 6 7 8',\n",
              " '8 17',\n",
              " '9 10 11 12 13',\n",
              " '11',\n",
              " '5',\n",
              " '9',\n",
              " '1',\n",
              " '5',\n",
              " '4 5',\n",
              " '6 7 8 9',\n",
              " '5',\n",
              " '7 8 9',\n",
              " '5 6 10 11',\n",
              " '4 5 6 10',\n",
              " '7 8',\n",
              " '4',\n",
              " '7 8 9',\n",
              " '6 7',\n",
              " '5',\n",
              " '24',\n",
              " '1',\n",
              " '6 7 27',\n",
              " '6 7',\n",
              " '7 8 9',\n",
              " '6 7 9',\n",
              " '8 9 10 11 12 13',\n",
              " '7 8 9 10 11 12',\n",
              " '6 7',\n",
              " '9',\n",
              " '10',\n",
              " '6',\n",
              " '7 8 9',\n",
              " '13',\n",
              " '4 5 6 7',\n",
              " '4 5 15',\n",
              " '3',\n",
              " '6 7',\n",
              " '6 7',\n",
              " '3',\n",
              " '2',\n",
              " '5 8 9',\n",
              " '5',\n",
              " '4',\n",
              " '5 6 7 8',\n",
              " '9 10',\n",
              " '6 7',\n",
              " '3 4',\n",
              " '4',\n",
              " '12',\n",
              " '7',\n",
              " '3 4 5',\n",
              " '3',\n",
              " '5',\n",
              " '8 9 10 11 18 19',\n",
              " '6 7 12 13',\n",
              " '10',\n",
              " '6 7 11',\n",
              " '4 5 6',\n",
              " '3',\n",
              " '3',\n",
              " '9 27',\n",
              " '4 5',\n",
              " '4',\n",
              " '6 7 11',\n",
              " '26 37',\n",
              " '1',\n",
              " '8 9',\n",
              " '9',\n",
              " '8 13',\n",
              " '6 7 8 9 10',\n",
              " '9 10',\n",
              " '7',\n",
              " '8',\n",
              " '8 11',\n",
              " '12',\n",
              " '6 7 8',\n",
              " '6',\n",
              " '5',\n",
              " '6 7 8',\n",
              " '13 14 15',\n",
              " '4 5 9',\n",
              " '8 10 12 13 14',\n",
              " '8 11',\n",
              " '1',\n",
              " '7',\n",
              " '2 3 4',\n",
              " '19 30',\n",
              " '6 7',\n",
              " '4',\n",
              " '20',\n",
              " '6 7 8',\n",
              " '7 8',\n",
              " '4',\n",
              " '6 7',\n",
              " '9',\n",
              " '7 8 9 10 11',\n",
              " '8 25',\n",
              " '4',\n",
              " '6 7 8 9',\n",
              " '5 6',\n",
              " '3 4',\n",
              " '5 6',\n",
              " '3',\n",
              " '5 6',\n",
              " '8 9 10',\n",
              " '3 6',\n",
              " '5 6',\n",
              " '3',\n",
              " '13',\n",
              " '16',\n",
              " '8',\n",
              " '7 8',\n",
              " '3',\n",
              " '5 6',\n",
              " '5',\n",
              " '6 7',\n",
              " '5',\n",
              " '4 5 6',\n",
              " '9 10 11',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_BQUg8UB2Ri"
      },
      "source": [
        "# Pre process tweet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCYo4gzcB6Gx"
      },
      "source": [
        "## Hindi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtLvGHliB4kp"
      },
      "source": [
        "import string,re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6gQTUZiCEVG"
      },
      "source": [
        "def preprocess_tweet(text):\n",
        "\n",
        "#     # Check characters to see if they are in punctuation\n",
        "#     nopunc = [char for char in text if char not in string.punctuation]\n",
        "#     # Join the characters again to form the string.\n",
        "#     nopunc = ''.join(nopunc)\n",
        "    # convert text to lower-case\n",
        "#     nopunc = nopunc.lower()\n",
        "    # remove URLs\n",
        "    nopunc = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))', '', text)\n",
        "    nopunc = re.sub(r'http\\S+', '', nopunc)\n",
        "    # remove usernames\n",
        "    nopunc = re.sub('@[^\\s]+', '', nopunc)\n",
        "    \n",
        "    nopunc = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\-\\\\\\/\\,])', r' ', nopunc)\n",
        "    nopunc = re.sub(r'([\\;\\:\\|•«\\n])', ' ', nopunc)\n",
        "    # remove the # in #hashtag\n",
        "#     nopunc = re.sub(r'#([^\\s]+)', r'\\1', nopunc)\n",
        "    nopunc = re.sub(r'#\\w*','',nopunc)\n",
        "    # remove repeated characters\n",
        "#     nopunc = word_tokenize(nopunc)\n",
        "    # remove stopwords from final word list\n",
        "#     return [word for word in nopunc if word not in stopwords.words('english')]\n",
        "    try:\n",
        "        nopunc = re.sub(u'([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF])', '',nopunc)\n",
        "    except re.error:\n",
        "        nopunc = re.sub(u'([\\u2600-\\u27BF])|([\\uD83C][\\uDF00-\\uDFFF])|([\\uD83D][\\uDC00-\\uDE4F])|([\\uD83D][\\uDE80-\\uDEFF])', '', nopunc)\n",
        "    nopunc = [char for char in nopunc if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "    return nopunc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQKojc7TCGFk"
      },
      "source": [
        "for i in range(0,len(tweet)):\n",
        "    tweet[i] = preprocess_tweet(tweet[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrJebUbgCIoS"
      },
      "source": [
        "all_locations = []\n",
        "for i in range(0, len(location1)):\n",
        "    temp = []\n",
        "    if type(location1[i]) == str:\n",
        "        temp.append(location1[i])\n",
        "    if type(location2[i]) == str:\n",
        "        temp.append(location2[i])\n",
        "    if type(location3[i]) == str:\n",
        "        temp.append(location3[i])\n",
        "    if type(location4[i]) == str:\n",
        "        temp.append(location4[i])\n",
        "    if type(location5[i]) == str:\n",
        "        temp.append(location5[i])\n",
        "    all_locations.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f39fIeU6CSg8"
      },
      "source": [
        "all_locations_sep = []\n",
        "for i in range(0,len(all_locations)):\n",
        "    t = []\n",
        "    for j in range(0,len(all_locations[i])):\n",
        "        xx = all_locations[i][j].split()\n",
        "        for k in range(0, len(xx)):\n",
        "            t.append(xx[k])\n",
        "    all_locations_sep.append(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWHim_9ZC2_k"
      },
      "source": [
        "## English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERhhD9EFG36C"
      },
      "source": [
        "def preprocess_tweet(text):\n",
        "\n",
        "#     # Check characters to see if they are in punctuation\n",
        "#     nopunc = [char for char in text if char not in string.punctuation]\n",
        "#     # Join the characters again to form the string.\n",
        "#     nopunc = ''.join(nopunc)\n",
        "    # convert text to lower-case\n",
        "#     nopunc = nopunc.lower()\n",
        "    # remove URLs\n",
        "    nopunc = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))', '', text)\n",
        "    nopunc = re.sub(r'http\\S+', '', nopunc)\n",
        "    # remove usernames\n",
        "    nopunc = re.sub('@[^\\s]+', '', nopunc)\n",
        "    \n",
        "    nopunc = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\-\\\\\\/\\,])', r' ', nopunc)\n",
        "    nopunc = re.sub(r'([\\;\\:\\|•«\\n])', ' ', nopunc)\n",
        "    # remove the # in #hashtag\n",
        "#     nopunc = re.sub(r'#([^\\s]+)', r'\\1', nopunc)\n",
        "    nopunc = re.sub(r'#\\w*','',nopunc)\n",
        "    # remove repeated characters\n",
        "#     nopunc = word_tokenize(nopunc)\n",
        "    # remove stopwords from final word list\n",
        "#     return [word for word in nopunc if word not in stopwords.words('english')]\n",
        "    try:\n",
        "        nopunc = re.sub(u'([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF])', '',nopunc)\n",
        "    except re.error:\n",
        "        nopunc = re.sub(u'([\\u2600-\\u27BF])|([\\uD83C][\\uDF00-\\uDFFF])|([\\uD83D][\\uDC00-\\uDE4F])|([\\uD83D][\\uDE80-\\uDEFF])', '', nopunc)\n",
        "    nopunc = [char for char in nopunc if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "    return nopunc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCcDcZnCG450"
      },
      "source": [
        "for i in range(0,len(tweet_eng)):\n",
        "    tweet_eng[i] = preprocess_tweet(tweet_eng[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60TWnwHpFCLq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "29d04bbe-aa2f-42b0-9c39-14f9f05cb83f"
      },
      "source": [
        "labels[0].split()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['6', '7']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqO_bjLGCT2z"
      },
      "source": [
        "all_locations_sep_eng = []\n",
        "for i in range(0,len(labels)):\n",
        "    # print(i)\n",
        "    t = []\n",
        "    xx = labels[i].split()\n",
        "    for k in range(0, len(xx)):\n",
        "            t.append(int((xx[k]))-1)\n",
        "    all_locations_sep_eng.append(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9uqFFu2F0A_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9eb0c24c-1ea4-4107-b0b9-be7a1158fbe1"
      },
      "source": [
        "all_locations_sep_eng"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 6],\n",
              " [7],\n",
              " [10],\n",
              " [15],\n",
              " [5],\n",
              " [15],\n",
              " [3, 4],\n",
              " [31],\n",
              " [7, 8],\n",
              " [6, 7],\n",
              " [22],\n",
              " [5, 6],\n",
              " [1, 2],\n",
              " [7, 12],\n",
              " [11, 12],\n",
              " [8],\n",
              " [8],\n",
              " [6],\n",
              " [4],\n",
              " [4],\n",
              " [8],\n",
              " [25],\n",
              " [13],\n",
              " [6, 18],\n",
              " [25],\n",
              " [8],\n",
              " [6],\n",
              " [16, 17, 18, 19, 20, 21, 22, 23],\n",
              " [5, 6, 7],\n",
              " [8],\n",
              " [13, 40],\n",
              " [3, 4, 8],\n",
              " [7, 8, 9, 10],\n",
              " [17],\n",
              " [9, 10, 11, 12],\n",
              " [12, 22],\n",
              " [10, 11],\n",
              " [8, 9, 10],\n",
              " [3, 4],\n",
              " [8, 9, 16],\n",
              " [7],\n",
              " [3, 4, 5],\n",
              " [0],\n",
              " [14, 15, 16, 21, 25],\n",
              " [4],\n",
              " [29, 30],\n",
              " [3],\n",
              " [7],\n",
              " [6, 7],\n",
              " [8, 9, 10],\n",
              " [7, 8, 9],\n",
              " [19],\n",
              " [3, 4, 8],\n",
              " [8, 9],\n",
              " [8],\n",
              " [5, 6, 7, 11],\n",
              " [8],\n",
              " [4, 5],\n",
              " [12],\n",
              " [4, 7],\n",
              " [1, 13],\n",
              " [6],\n",
              " [4, 5],\n",
              " [6, 7, 8],\n",
              " [1, 9],\n",
              " [4, 5],\n",
              " [4],\n",
              " [1, 2, 3, 4],\n",
              " [7, 8, 9],\n",
              " [8],\n",
              " [5],\n",
              " [0, 1],\n",
              " [9],\n",
              " [13],\n",
              " [7, 8],\n",
              " [7],\n",
              " [8, 9],\n",
              " [8, 9, 10, 11],\n",
              " [3],\n",
              " [9, 12, 16, 36],\n",
              " [9],\n",
              " [7],\n",
              " [5, 6, 10],\n",
              " [1, 2],\n",
              " [3],\n",
              " [0],\n",
              " [3, 4, 5, 9],\n",
              " [8, 9],\n",
              " [10, 11],\n",
              " [10, 11],\n",
              " [6],\n",
              " [5, 6],\n",
              " [15],\n",
              " [4],\n",
              " [2],\n",
              " [6, 7],\n",
              " [0, 1, 2, 3, 5],\n",
              " [3, 7],\n",
              " [12],\n",
              " [6, 7, 8, 9],\n",
              " [4],\n",
              " [0, 1, 2, 3, 4, 6],\n",
              " [4, 30],\n",
              " [5, 6],\n",
              " [2, 3],\n",
              " [4, 6, 7],\n",
              " [3],\n",
              " [4],\n",
              " [3],\n",
              " [15],\n",
              " [5],\n",
              " [8, 10, 11, 14],\n",
              " [6, 7],\n",
              " [6],\n",
              " [13],\n",
              " [9],\n",
              " [5, 6, 10],\n",
              " [16],\n",
              " [8],\n",
              " [9, 10],\n",
              " [14],\n",
              " [4, 5, 6],\n",
              " [9],\n",
              " [4],\n",
              " [5, 6],\n",
              " [2, 3],\n",
              " [5, 6],\n",
              " [8, 9],\n",
              " [8, 9],\n",
              " [23],\n",
              " [5, 6],\n",
              " [8, 10],\n",
              " [2, 3, 4],\n",
              " [1, 7],\n",
              " [0, 1],\n",
              " [0, 1],\n",
              " [2, 3, 4, 5, 6],\n",
              " [4, 5, 6, 7, 9],\n",
              " [2, 3],\n",
              " [12, 13],\n",
              " [13, 14],\n",
              " [3, 7],\n",
              " [0, 1, 30, 31],\n",
              " [13],\n",
              " [4],\n",
              " [3],\n",
              " [4, 5, 6, 7],\n",
              " [1],\n",
              " [7, 8, 9, 10],\n",
              " [2],\n",
              " [3, 4, 5, 6, 7, 10],\n",
              " [9, 10],\n",
              " [4, 5],\n",
              " [4],\n",
              " [8, 9],\n",
              " [7, 8],\n",
              " [12],\n",
              " [19],\n",
              " [4, 5, 6],\n",
              " [8],\n",
              " [0, 1, 2],\n",
              " [6, 7],\n",
              " [7, 8],\n",
              " [0],\n",
              " [9, 10],\n",
              " [3, 6, 7],\n",
              " [5, 6, 7, 8],\n",
              " [3],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [5],\n",
              " [6],\n",
              " [13],\n",
              " [14],\n",
              " [0, 2, 3, 4],\n",
              " [11, 12],\n",
              " [7, 8, 9],\n",
              " [6, 7, 8],\n",
              " [3, 4],\n",
              " [2],\n",
              " [6, 7],\n",
              " [8, 9],\n",
              " [4, 5, 6],\n",
              " [3, 4, 8],\n",
              " [2, 4],\n",
              " [7, 8, 9],\n",
              " [9],\n",
              " [2],\n",
              " [2, 3, 6, 8, 10],\n",
              " [5],\n",
              " [3, 4, 5, 6, 7, 11],\n",
              " [4, 5, 9],\n",
              " [0],\n",
              " [7, 8, 9],\n",
              " [8, 9],\n",
              " [1, 2],\n",
              " [5, 6],\n",
              " [4, 5, 6, 7],\n",
              " [2],\n",
              " [4, 5, 6],\n",
              " [0],\n",
              " [2, 8, 9],\n",
              " [8],\n",
              " [7],\n",
              " [3],\n",
              " [5, 6, 9],\n",
              " [5],\n",
              " [8, 9],\n",
              " [4, 16, 24],\n",
              " [3],\n",
              " [4, 5, 6, 7],\n",
              " [4, 10],\n",
              " [0],\n",
              " [42],\n",
              " [7, 8],\n",
              " [2],\n",
              " [3],\n",
              " [4],\n",
              " [2, 3],\n",
              " [6, 7, 8, 9, 10],\n",
              " [4],\n",
              " [8, 9],\n",
              " [4, 5, 6, 7],\n",
              " [12],\n",
              " [6, 8, 14, 16],\n",
              " [2],\n",
              " [13],\n",
              " [6, 7, 8],\n",
              " [9],\n",
              " [3, 4, 5, 6, 10],\n",
              " [20, 21, 31],\n",
              " [4, 5, 6],\n",
              " [3],\n",
              " [5, 6],\n",
              " [5],\n",
              " [4, 5, 6, 10],\n",
              " [3, 22],\n",
              " [16],\n",
              " [5, 6, 7],\n",
              " [7, 8, 9],\n",
              " [2, 3, 5],\n",
              " [5],\n",
              " [3, 4, 5, 6, 7],\n",
              " [4],\n",
              " [5, 6],\n",
              " [9, 10],\n",
              " [0, 1],\n",
              " [5, 6, 7, 11],\n",
              " [5, 6],\n",
              " [8],\n",
              " [6, 12, 13, 14],\n",
              " [9],\n",
              " [7],\n",
              " [8, 16, 18],\n",
              " [7, 8, 9, 10],\n",
              " [6, 7, 8],\n",
              " [8],\n",
              " [0],\n",
              " [0, 4],\n",
              " [6, 7, 12, 13, 33, 34, 35, 36],\n",
              " [4],\n",
              " [7, 8],\n",
              " [1, 2],\n",
              " [6, 7],\n",
              " [4, 5, 6, 7],\n",
              " [5, 6],\n",
              " [0, 1, 2, 3],\n",
              " [8, 9, 10, 11, 12],\n",
              " [5, 6, 7, 8, 9],\n",
              " [7, 33],\n",
              " [7],\n",
              " [5, 6, 10],\n",
              " [5, 6, 7, 11],\n",
              " [9, 11],\n",
              " [7, 22],\n",
              " [28],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [4],\n",
              " [0, 7],\n",
              " [5],\n",
              " [2, 3],\n",
              " [15, 17],\n",
              " [5],\n",
              " [14],\n",
              " [5],\n",
              " [20, 45],\n",
              " [6],\n",
              " [0, 3, 4, 5, 6, 9],\n",
              " [3, 4, 5, 6, 13, 14, 15, 16],\n",
              " [3, 4, 8],\n",
              " [6, 7, 8],\n",
              " [3],\n",
              " [4, 8],\n",
              " [10, 11, 27],\n",
              " [5, 6, 10],\n",
              " [10],\n",
              " [14],\n",
              " [6, 9, 19, 23],\n",
              " [5],\n",
              " [2],\n",
              " [3, 6, 33, 39],\n",
              " [6],\n",
              " [9],\n",
              " [15],\n",
              " [8, 9, 10],\n",
              " [5],\n",
              " [1],\n",
              " [8, 9, 10, 11, 12, 13],\n",
              " [3],\n",
              " [6, 7, 8, 9],\n",
              " [7, 14],\n",
              " [7],\n",
              " [6, 8],\n",
              " [3],\n",
              " [6, 7],\n",
              " [9],\n",
              " [5, 10],\n",
              " [6, 7],\n",
              " [5, 6],\n",
              " [8, 9],\n",
              " [7, 8, 9],\n",
              " [4, 5],\n",
              " [8, 9, 10],\n",
              " [5, 6, 7],\n",
              " [10],\n",
              " [5, 6],\n",
              " [6, 7, 8],\n",
              " [9],\n",
              " [6, 7, 9],\n",
              " [0],\n",
              " [7],\n",
              " [8],\n",
              " [15],\n",
              " [9],\n",
              " [5, 6],\n",
              " [3, 4, 5, 6],\n",
              " [27],\n",
              " [11],\n",
              " [15],\n",
              " [9, 18],\n",
              " [7],\n",
              " [4],\n",
              " [8],\n",
              " [0, 6],\n",
              " [7],\n",
              " [0, 5],\n",
              " [7],\n",
              " [4, 5],\n",
              " [15],\n",
              " [8],\n",
              " [2],\n",
              " [1],\n",
              " [0],\n",
              " [8, 9, 10],\n",
              " [9],\n",
              " [9, 10, 11, 12],\n",
              " [4],\n",
              " [12, 13, 14],\n",
              " [11],\n",
              " [5, 9],\n",
              " [1],\n",
              " [5, 6, 7],\n",
              " [4],\n",
              " [5],\n",
              " [4, 5],\n",
              " [7, 8],\n",
              " [10],\n",
              " [4],\n",
              " [2, 7],\n",
              " [10],\n",
              " [5, 6],\n",
              " [9],\n",
              " [7],\n",
              " [4],\n",
              " [6, 7],\n",
              " [13],\n",
              " [5, 6],\n",
              " [5],\n",
              " [2],\n",
              " [7],\n",
              " [2],\n",
              " [8],\n",
              " [6, 7],\n",
              " [7],\n",
              " [13, 14, 16, 17],\n",
              " [7, 22],\n",
              " [9, 10],\n",
              " [3],\n",
              " [3, 27],\n",
              " [7],\n",
              " [2, 3],\n",
              " [6],\n",
              " [5, 6, 7],\n",
              " [31],\n",
              " [20],\n",
              " [7],\n",
              " [7],\n",
              " [8, 9, 10],\n",
              " [7, 8],\n",
              " [9],\n",
              " [6, 7],\n",
              " [10],\n",
              " [5],\n",
              " [27],\n",
              " [6],\n",
              " [7, 9],\n",
              " [4, 5, 6],\n",
              " [16],\n",
              " [2],\n",
              " [2, 4],\n",
              " [3, 4],\n",
              " [18],\n",
              " [1, 10, 13],\n",
              " [4, 13],\n",
              " [7, 8],\n",
              " [3, 4],\n",
              " [11],\n",
              " [2, 3],\n",
              " [12],\n",
              " [6, 7],\n",
              " [3],\n",
              " [7, 8],\n",
              " [4, 5],\n",
              " [11],\n",
              " [5],\n",
              " [10, 11],\n",
              " [9, 10],\n",
              " [13],\n",
              " [6, 7],\n",
              " [7, 8],\n",
              " [8],\n",
              " [12],\n",
              " [9, 10, 29, 30],\n",
              " [6],\n",
              " [0, 1],\n",
              " [1, 2],\n",
              " [7],\n",
              " [5],\n",
              " [6],\n",
              " [17],\n",
              " [3, 6],\n",
              " [7],\n",
              " [2, 3, 4],\n",
              " [2],\n",
              " [24],\n",
              " [4],\n",
              " [8],\n",
              " [3],\n",
              " [5],\n",
              " [1, 2, 6, 7],\n",
              " [8],\n",
              " [8],\n",
              " [5, 6, 7],\n",
              " [6],\n",
              " [2, 5],\n",
              " [5, 10],\n",
              " [6, 7],\n",
              " [5, 6, 7],\n",
              " [5, 6, 7, 8],\n",
              " [3],\n",
              " [7],\n",
              " [8, 9],\n",
              " [7],\n",
              " [9],\n",
              " [6, 7, 8],\n",
              " [6],\n",
              " [2],\n",
              " [3],\n",
              " [16],\n",
              " [36, 37],\n",
              " [6, 7, 8],\n",
              " [16],\n",
              " [1, 2],\n",
              " [15],\n",
              " [7],\n",
              " [3],\n",
              " [2, 3, 5],\n",
              " [19],\n",
              " [8],\n",
              " [9, 10],\n",
              " [1, 2, 3],\n",
              " [16],\n",
              " [6, 7, 9],\n",
              " [6, 7, 8],\n",
              " [19],\n",
              " [7, 8],\n",
              " [10],\n",
              " [8, 9],\n",
              " [3, 4, 8],\n",
              " [2],\n",
              " [3],\n",
              " [5, 6, 7, 8],\n",
              " [5, 10],\n",
              " [4, 5, 7],\n",
              " [8, 22],\n",
              " [1],\n",
              " [9],\n",
              " [2, 3, 4],\n",
              " [4, 5, 6, 11, 12, 13],\n",
              " [13],\n",
              " [5, 6, 7],\n",
              " [2, 3, 4],\n",
              " [3],\n",
              " [9, 11],\n",
              " [10, 11],\n",
              " [5, 8],\n",
              " [0, 1],\n",
              " [9],\n",
              " [6, 7, 8],\n",
              " [5, 6, 7, 8],\n",
              " [4, 5, 6],\n",
              " [4],\n",
              " [6],\n",
              " [8, 9],\n",
              " [22],\n",
              " [7],\n",
              " [5, 6],\n",
              " [7, 17],\n",
              " [6, 51],\n",
              " [1, 2, 11, 12, 25],\n",
              " [4],\n",
              " [7],\n",
              " [1, 2],\n",
              " [2],\n",
              " [7, 8],\n",
              " [1],\n",
              " [1],\n",
              " [6],\n",
              " [6],\n",
              " [0],\n",
              " [2, 3],\n",
              " [4, 5],\n",
              " [3],\n",
              " [3, 4],\n",
              " [6, 7],\n",
              " [14],\n",
              " [0],\n",
              " [3, 4, 5, 6, 10],\n",
              " [2, 3],\n",
              " [5, 6, 7],\n",
              " [5, 6],\n",
              " [2],\n",
              " [9],\n",
              " [30],\n",
              " [4, 5, 6, 7],\n",
              " [4],\n",
              " [6, 7],\n",
              " [3, 4, 5],\n",
              " [3],\n",
              " [8, 9],\n",
              " [4],\n",
              " [11],\n",
              " [4, 5],\n",
              " [4],\n",
              " [6, 7, 8],\n",
              " [3],\n",
              " [0, 13],\n",
              " [4],\n",
              " [8, 9, 10],\n",
              " [5, 6],\n",
              " [3, 7, 8],\n",
              " [7],\n",
              " [3, 4],\n",
              " [5, 6],\n",
              " [7],\n",
              " [8, 9],\n",
              " [6, 7],\n",
              " [7, 8],\n",
              " [4],\n",
              " [9],\n",
              " [4],\n",
              " [6],\n",
              " [2, 3, 4],\n",
              " [6],\n",
              " [7, 8, 9],\n",
              " [6, 7],\n",
              " [6],\n",
              " [2, 3],\n",
              " [6, 7, 8],\n",
              " [3],\n",
              " [0],\n",
              " [2],\n",
              " [3, 4, 5],\n",
              " [8, 9],\n",
              " [8, 9, 11],\n",
              " [3, 4],\n",
              " [5, 6],\n",
              " [5, 8, 9],\n",
              " [4, 5, 6],\n",
              " [2],\n",
              " [6],\n",
              " [4],\n",
              " [5],\n",
              " [10, 11],\n",
              " [5, 7, 8],\n",
              " [7, 8],\n",
              " [9],\n",
              " [9, 12],\n",
              " [0, 1, 7, 8, 13, 14, 15, 21, 26, 28, 29],\n",
              " [5, 19],\n",
              " [0, 10],\n",
              " [3],\n",
              " [5, 6],\n",
              " [10, 18, 27, 28, 29],\n",
              " [7, 8, 9],\n",
              " [5, 6, 7, 8],\n",
              " [4],\n",
              " [0, 5, 6],\n",
              " [28],\n",
              " [0, 12, 13, 14],\n",
              " [5, 6, 7],\n",
              " [5],\n",
              " [5, 6],\n",
              " [0],\n",
              " [0, 10],\n",
              " [7],\n",
              " [20, 28, 30, 31, 32, 33],\n",
              " [2],\n",
              " [2],\n",
              " [3, 6],\n",
              " [13],\n",
              " [25],\n",
              " [9],\n",
              " [5, 6, 10],\n",
              " [4, 5, 6, 11, 12, 13],\n",
              " [3],\n",
              " [6, 10, 11],\n",
              " [6],\n",
              " [7, 8, 9, 10],\n",
              " [11],\n",
              " [1],\n",
              " [6],\n",
              " [8, 9],\n",
              " [7],\n",
              " [7, 8],\n",
              " [5, 6, 7],\n",
              " [6, 7],\n",
              " [5],\n",
              " [0],\n",
              " [18],\n",
              " [8, 9, 10],\n",
              " [5, 6],\n",
              " [0],\n",
              " [0, 1, 2],\n",
              " [5, 6],\n",
              " [5, 6, 7],\n",
              " [1, 2],\n",
              " [4],\n",
              " [5],\n",
              " [4, 10, 11, 15],\n",
              " [5, 6, 7],\n",
              " [3, 4, 5, 9, 10],\n",
              " [47],\n",
              " [19],\n",
              " [1],\n",
              " [6, 7],\n",
              " [6, 7, 8],\n",
              " [9],\n",
              " [12, 13],\n",
              " [13, 17],\n",
              " [2, 3, 10],\n",
              " [7, 8],\n",
              " [9],\n",
              " [7],\n",
              " [7],\n",
              " [5, 6, 10],\n",
              " [1],\n",
              " [5, 6, 7, 8],\n",
              " [7],\n",
              " [4, 5],\n",
              " [3, 4, 5, 6],\n",
              " [7, 8, 9, 10, 11, 12, 13],\n",
              " [14, 23],\n",
              " [4, 5, 6, 7],\n",
              " [6, 7],\n",
              " [7],\n",
              " [0],\n",
              " [6],\n",
              " [29],\n",
              " [30],\n",
              " [0],\n",
              " [1],\n",
              " [3, 4, 7, 8, 12],\n",
              " [13, 14],\n",
              " [0, 1, 2, 4, 5, 6],\n",
              " [5, 6, 7],\n",
              " [6],\n",
              " [3, 6, 7, 8],\n",
              " [7, 8],\n",
              " [14, 17],\n",
              " [3],\n",
              " [7, 8, 9, 10],\n",
              " [9],\n",
              " [3, 4, 5, 9],\n",
              " [13],\n",
              " [7, 8],\n",
              " [9, 33],\n",
              " [10, 11],\n",
              " [0],\n",
              " [4],\n",
              " [23],\n",
              " [4, 7, 10, 12],\n",
              " [3],\n",
              " [10, 28, 35],\n",
              " [9],\n",
              " [3, 4, 5, 7],\n",
              " [14],\n",
              " [2],\n",
              " [23, 31],\n",
              " [9, 10],\n",
              " [6],\n",
              " [10],\n",
              " [10, 22],\n",
              " [6, 7, 8],\n",
              " [0, 1],\n",
              " [13, 14, 15, 16],\n",
              " [7, 8, 9, 10],\n",
              " [5, 6, 10],\n",
              " [4],\n",
              " [5, 6],\n",
              " [3],\n",
              " [4, 5, 6, 7],\n",
              " [13],\n",
              " [5, 6, 7, 8],\n",
              " [5, 6],\n",
              " [7, 8, 9],\n",
              " [5, 16, 17, 18, 27],\n",
              " [5, 6],\n",
              " [7],\n",
              " [9, 10, 11, 12],\n",
              " [6, 7, 8],\n",
              " [10],\n",
              " [0, 1],\n",
              " [20],\n",
              " [0, 2, 22, 23, 24, 25, 26, 29],\n",
              " [38],\n",
              " [4, 5, 6],\n",
              " [6],\n",
              " [5, 6],\n",
              " [6],\n",
              " [7, 8],\n",
              " [13],\n",
              " [8],\n",
              " [7, 8, 9, 11, 12],\n",
              " [6],\n",
              " [8, 16],\n",
              " [5],\n",
              " [4, 5, 6, 7, 8, 9],\n",
              " [0],\n",
              " [14],\n",
              " [2, 3, 4],\n",
              " [11],\n",
              " [5, 6, 7],\n",
              " [4, 5],\n",
              " [0, 5],\n",
              " [13, 25, 36],\n",
              " [0],\n",
              " [8, 17, 20],\n",
              " [5, 6, 7, 8, 9],\n",
              " [4],\n",
              " [5],\n",
              " [2, 3],\n",
              " [6],\n",
              " [12],\n",
              " [1, 2, 3, 4],\n",
              " [6, 7, 8, 9, 15, 16, 17, 18],\n",
              " [1, 2, 6, 7],\n",
              " [9],\n",
              " [3],\n",
              " [4, 5, 6, 7],\n",
              " [9],\n",
              " [6, 7, 8],\n",
              " [0],\n",
              " [5],\n",
              " [11],\n",
              " [9, 10],\n",
              " [1, 6],\n",
              " [5],\n",
              " [3, 4],\n",
              " [2, 3],\n",
              " [18],\n",
              " [8, 9],\n",
              " [3],\n",
              " [5],\n",
              " [14],\n",
              " [12],\n",
              " [26],\n",
              " [2, 3],\n",
              " [8],\n",
              " [3, 4],\n",
              " [7, 9],\n",
              " [5, 6, 7, 11],\n",
              " [1, 2, 3],\n",
              " [5],\n",
              " [0],\n",
              " [2, 3, 4, 8, 9, 10, 16, 17, 18, 31, 34],\n",
              " [5, 6, 10],\n",
              " [6, 7],\n",
              " [4, 5, 32],\n",
              " [5, 6, 12, 13],\n",
              " [0],\n",
              " [2, 3],\n",
              " [10, 11],\n",
              " [9, 10],\n",
              " [0],\n",
              " [2, 6, 15, 27],\n",
              " [7, 8],\n",
              " [7],\n",
              " [7, 8, 9],\n",
              " [6, 7, 8, 9],\n",
              " [4, 5, 7],\n",
              " [10, 39],\n",
              " [4],\n",
              " [1, 3, 7, 9],\n",
              " [2],\n",
              " [4],\n",
              " [10, 11],\n",
              " [8, 9, 10],\n",
              " [14, 15],\n",
              " [9],\n",
              " [8, 9],\n",
              " [3],\n",
              " [2, 5, 6, 9, 18, 20, 21, 23],\n",
              " [19, 20, 21],\n",
              " [2, 12, 13, 33, 34],\n",
              " [2, 14],\n",
              " [7, 8, 9, 10, 11],\n",
              " [8, 9],\n",
              " [19],\n",
              " [4, 5, 18, 34],\n",
              " [8, 9],\n",
              " [6, 7, 8],\n",
              " [16],\n",
              " [20, 21],\n",
              " [7, 8],\n",
              " [5],\n",
              " [1, 2, 6, 7],\n",
              " [0],\n",
              " [4],\n",
              " [10, 11],\n",
              " [39],\n",
              " [13],\n",
              " [28],\n",
              " [4, 5, 6],\n",
              " [6, 7, 8, 12, 13],\n",
              " [4],\n",
              " [12],\n",
              " [2, 3, 11, 12],\n",
              " [11],\n",
              " [0],\n",
              " [10, 11],\n",
              " [5, 6, 7],\n",
              " [7, 8],\n",
              " [6, 7, 8],\n",
              " [8, 13],\n",
              " [5, 6, 7, 8],\n",
              " [6, 7, 8],\n",
              " [8, 9, 10],\n",
              " [12],\n",
              " [1],\n",
              " [1],\n",
              " [18],\n",
              " [8],\n",
              " [9],\n",
              " [1, 2],\n",
              " [6, 7],\n",
              " [4, 9, 17],\n",
              " [8, 9, 10, 11],\n",
              " [4, 5, 6],\n",
              " [9],\n",
              " [9, 10],\n",
              " [4, 5, 6],\n",
              " [8, 9, 10],\n",
              " [6, 7],\n",
              " [9, 21],\n",
              " [7, 8],\n",
              " [1, 2, 3, 4],\n",
              " [4, 30, 33, 45],\n",
              " [6, 7, 8],\n",
              " [8, 9],\n",
              " [3, 4, 5, 6, 7],\n",
              " [7, 16],\n",
              " [8, 9, 10, 11, 12],\n",
              " [10],\n",
              " [4],\n",
              " [8],\n",
              " [0],\n",
              " [4],\n",
              " [3, 4],\n",
              " [5, 6, 7, 8],\n",
              " [4],\n",
              " [6, 7, 8],\n",
              " [4, 5, 9, 10],\n",
              " [3, 4, 5, 9],\n",
              " [6, 7],\n",
              " [3],\n",
              " [6, 7, 8],\n",
              " [5, 6],\n",
              " [4],\n",
              " [23],\n",
              " [0],\n",
              " [5, 6, 26],\n",
              " [5, 6],\n",
              " [6, 7, 8],\n",
              " [5, 6, 8],\n",
              " [7, 8, 9, 10, 11, 12],\n",
              " [6, 7, 8, 9, 10, 11],\n",
              " [5, 6],\n",
              " [8],\n",
              " [9],\n",
              " [5],\n",
              " [6, 7, 8],\n",
              " [12],\n",
              " [3, 4, 5, 6],\n",
              " [3, 4, 14],\n",
              " [2],\n",
              " [5, 6],\n",
              " [5, 6],\n",
              " [2],\n",
              " [1],\n",
              " [4, 7, 8],\n",
              " [4],\n",
              " [3],\n",
              " [4, 5, 6, 7],\n",
              " [8, 9],\n",
              " [5, 6],\n",
              " [2, 3],\n",
              " [3],\n",
              " [11],\n",
              " [6],\n",
              " [2, 3, 4],\n",
              " [2],\n",
              " [4],\n",
              " [7, 8, 9, 10, 17, 18],\n",
              " [5, 6, 11, 12],\n",
              " [9],\n",
              " [5, 6, 10],\n",
              " [3, 4, 5],\n",
              " [2],\n",
              " [2],\n",
              " [8, 26],\n",
              " [3, 4],\n",
              " [3],\n",
              " [5, 6, 10],\n",
              " [25, 36],\n",
              " [0],\n",
              " [7, 8],\n",
              " [8],\n",
              " [7, 12],\n",
              " [5, 6, 7, 8, 9],\n",
              " [8, 9],\n",
              " [6],\n",
              " [7],\n",
              " [7, 10],\n",
              " [11],\n",
              " [5, 6, 7],\n",
              " [5],\n",
              " [4],\n",
              " [5, 6, 7],\n",
              " [12, 13, 14],\n",
              " [3, 4, 8],\n",
              " [7, 9, 11, 12, 13],\n",
              " [7, 10],\n",
              " [0],\n",
              " [6],\n",
              " [1, 2, 3],\n",
              " [18, 29],\n",
              " [5, 6],\n",
              " [3],\n",
              " [19],\n",
              " [5, 6, 7],\n",
              " [6, 7],\n",
              " [3],\n",
              " [5, 6],\n",
              " [8],\n",
              " [6, 7, 8, 9, 10],\n",
              " [7, 24],\n",
              " [3],\n",
              " [5, 6, 7, 8],\n",
              " [4, 5],\n",
              " [2, 3],\n",
              " [4, 5],\n",
              " [2],\n",
              " [4, 5],\n",
              " [7, 8, 9],\n",
              " [2, 5],\n",
              " [4, 5],\n",
              " [2],\n",
              " [12],\n",
              " [15],\n",
              " [7],\n",
              " [6, 7],\n",
              " [2],\n",
              " [4, 5],\n",
              " [4],\n",
              " [5, 6],\n",
              " [4],\n",
              " [3, 4, 5],\n",
              " [8, 9, 10],\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3_0LR_xGALD"
      },
      "source": [
        "# Function to tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9Ufdc32GDAl"
      },
      "source": [
        "## Hindi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es7YON93GClp"
      },
      "source": [
        "import string, re, sys, codecs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwXZROoFGK7F"
      },
      "source": [
        "# from indicnlp.common import IndicNlpException\n",
        "\n",
        "### tokenizer patterns \n",
        "triv_tokenizer_indic_pat=re.compile(r'(['+string.punctuation+r'\\u0964\\u0965'+r'])')\n",
        "triv_tokenizer_urdu_pat=re.compile(r'(['+string.punctuation+r'\\u0609\\u060A\\u060C\\u061E\\u066A\\u066B\\u066C\\u066D\\u06D4'+r'])')\n",
        "\n",
        "## date, numbers, section/article numbering\n",
        "pat_num_seq=re.compile(r'([0-9]+ [,.:/] )+[0-9]+')\n",
        "\n",
        "def trivial_tokenize_indic(s): \n",
        "    \"\"\"\n",
        "    A trivial tokenizer which just tokenizes on the punctuation boundaries. This also includes punctuations for the Indian language scripts\n",
        "      - the purna virama and the deergha virama\n",
        "    returns a list of tokens   \n",
        "    \"\"\"\n",
        "    tok_str=triv_tokenizer_indic_pat.sub(r' \\1 ',s.replace('\\t',' '))\n",
        "#     return re.sub(r'[ ]+',' ',tok_str).strip(' ').split(' ')\n",
        "\n",
        "    s=re.sub(r'[ ]+',' ',tok_str).strip(' ')\n",
        "    \n",
        "    # do not tokenize numbers and dates\n",
        "    new_s=''\n",
        "    prev=0\n",
        "    for m in pat_num_seq.finditer(s):\n",
        "        start=m.start()\n",
        "        end=m.end()\n",
        "        if start>prev:\n",
        "            new_s=new_s+s[prev:start]\n",
        "            new_s=new_s+s[start:end].replace(' ','')\n",
        "            prev=end\n",
        "   \n",
        "    new_s=new_s+s[prev:]\n",
        "    s=new_s\n",
        "    \n",
        "    return s.split(' ')\n",
        "\n",
        "def trivial_tokenize_urdu(s): \n",
        "    \"\"\"\n",
        "    A trivial tokenizer which just tokenizes on the punctuation boundaries. This also includes punctuations for the Urdu script.\n",
        "    These punctuations characters were identified from the Unicode database for Arabic script by looking for punctuation symbols.\n",
        "    returns a list of tokens   \n",
        "    \"\"\"\n",
        "    tok_str=triv_tokenizer_urdu_pat.sub(r' \\1 ',s.replace('\\t',' '))\n",
        "    return re.sub(r'[ ]+',' ',tok_str).strip(' ').split(' ')\n",
        "\n",
        "def trivial_tokenize(s,lang='hi'): \n",
        "    \"\"\"\n",
        "    Trivial tokenizer for languages in the Indian sub-continent\n",
        "    \"\"\"\n",
        "    if lang=='ur':\n",
        "        return trivial_tokenize_urdu(s)\n",
        "    else:\n",
        "        return trivial_tokenize_indic(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0bsmapdHNxE"
      },
      "source": [
        "## English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox2tOiKXKXyQ"
      },
      "source": [
        "\n",
        "# import nltk\n",
        "# nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHJGOXgDGPq1"
      },
      "source": [
        "# from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eVs_ZiTHfVK"
      },
      "source": [
        "# One hot encode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmcBwpfPHirB"
      },
      "source": [
        "## Hindi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ7YmQOfHTVs"
      },
      "source": [
        "def boolean_vec(tweet):\n",
        "    import math\n",
        "    one_hot_encoded=[]\n",
        "    for i in range(0,len(tweet)):\n",
        "        tText = tweet[i]\n",
        "        splits = trivial_tokenize(tText)\n",
        "        temp = [0]*len(splits)\n",
        "        for x in range(0,len(splits)):\n",
        "            for l in all_locations_sep[i]:\n",
        "                if l==splits[x]:\n",
        "                    temp[x] = 1\n",
        "#             if l1==x or l1 in x:\n",
        "#                 temp.append(1)\n",
        "#             if type(l2)==str and (l2==x or l2 in x):\n",
        "#                 temp.append(1)\n",
        "#             if type(l3)==str and (l3==x or l3 in x):\n",
        "#                 temp.append(1)\n",
        "#             if type(l4)==str and (l4==x or l4 in x):\n",
        "#                 temp.append(1)\n",
        "#             if type(l5)==str and (l5==x or l5 in x):\n",
        "#                 temp.append(1)\n",
        "#             else:\n",
        "#                 temp.append(0)\n",
        "        one_hot_encoded.append(temp)\n",
        "        temp=[]\n",
        "    return one_hot_encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22u2UZGKH6Ta"
      },
      "source": [
        "one_hot_encoded = boolean_vec(tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ5YPkuTH8Cz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "135f2e51-ff08-482d-a08c-8c938949e7bd"
      },
      "source": [
        "maxlen = 0\n",
        "for i in range(0,len(one_hot_encoded)):\n",
        "    maxlen = max(len(one_hot_encoded[i]),maxlen)\n",
        "print(maxlen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swki7JxWH92S"
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = maxlen #72"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGbeRXuKIAfF"
      },
      "source": [
        "for i in range(0,len(one_hot_encoded)):\n",
        "    pad_len = MAX_SEQUENCE_LENGTH - len(one_hot_encoded[i])\n",
        "    for j in range(0,pad_len):\n",
        "        one_hot_encoded[i].append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrQpAwvHICJs"
      },
      "source": [
        "for i in range(0,len(one_hot_encoded)):\n",
        "    if(len(one_hot_encoded[i]) != MAX_SEQUENCE_LENGTH):\n",
        "        print(\"Not encoded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3m7q3gFIKbe"
      },
      "source": [
        "## English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVgZZ9x-IIBX"
      },
      "source": [
        "def boolean_vec_eng(tweet):\n",
        "    import math\n",
        "    one_hot_encoded=[]\n",
        "    for i in range(0,len(tweet)):\n",
        "        tText = tweet[i]\n",
        "        splits = trivial_tokenize(tText)\n",
        "        temp = [0]*len(splits)\n",
        "        bound = list(range(0,len(splits)))\n",
        "        # for x in range(0,len(splits)):\n",
        "        for l in all_locations_sep_eng[i]:\n",
        "            if l in bound:\n",
        "                temp[l] = 1\n",
        "#             if l1==x or l1 in x:\n",
        "#                 temp.append(1)\n",
        "#             if type(l2)==str and (l2==x or l2 in x):\n",
        "#                 temp.append(1)\n",
        "#             if type(l3)==str and (l3==x or l3 in x):\n",
        "#                 temp.append(1)\n",
        "#             if type(l4)==str and (l4==x or l4 in x):\n",
        "#                 temp.append(1)\n",
        "#             if type(l5)==str and (l5==x or l5 in x):\n",
        "#                 temp.append(1)\n",
        "#             else:\n",
        "#                 temp.append(0)\n",
        "        one_hot_encoded.append(temp)\n",
        "        temp=[]\n",
        "    return one_hot_encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_MzRzmqJrJq"
      },
      "source": [
        "one_hot_encoded_eng = boolean_vec_eng(tweet_eng)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WwtmYxsZjNv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5c0f6037-4707-41f5-ff11-3b4b3d3ee622"
      },
      "source": [
        "tweet_eng[176]\n",
        "all_locations_sep_eng[176]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 8, 9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-03zZmXLNxm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "4e0f8670-8771-413b-84b8-f4a8cae7cd6a"
      },
      "source": [
        "i = 176\n",
        "m = trivial_tokenize(tweet_eng[i])\n",
        "for j in range(0,len(m)):\n",
        "    print(m[j],\":\",one_hot_encoded_eng[i][j])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "earthquake : 0\n",
            "usgs : 0\n",
            "forecast : 0\n",
            "m : 0\n",
            "km : 0\n",
            "n : 0\n",
            "of : 0\n",
            "chichi : 1\n",
            "shima : 1\n",
            "japan : 1\n",
            "time : 0\n",
            "utc : 0\n",
            "at : 0\n",
            "epicenter : 0\n",
            "location : 0\n",
            "n : 0\n",
            "e : 0\n",
            "dep : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbBkqi8rP_c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5a655438-e6bb-4824-d7a5-6a72f4d56c61"
      },
      "source": [
        "maxlen_eng = 0\n",
        "for i in range(0,len(one_hot_encoded_eng)):\n",
        "    maxlen_eng = max(len(one_hot_encoded_eng[i]),maxlen_eng)\n",
        "print(maxlen_eng)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63WtV5ZzQNHa"
      },
      "source": [
        "for i in range(0,len(one_hot_encoded_eng)):\n",
        "    pad_len = MAX_SEQUENCE_LENGTH - len(one_hot_encoded_eng[i])\n",
        "    for j in range(0,pad_len):\n",
        "        one_hot_encoded_eng[i].append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIspsMqxQTaU"
      },
      "source": [
        "for i in range(0,len(one_hot_encoded_eng)):\n",
        "    if(len(one_hot_encoded_eng[i]) != MAX_SEQUENCE_LENGTH):\n",
        "        print(\"Not encoded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaLKFV8wMJg2"
      },
      "source": [
        "# Embedding word vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkcC9e11RMlA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e0ad1500-85f2-4d33-a60d-55e01717cc58"
      },
      "source": [
        "print(len(combined_df),len(tweet),len(one_hot_encoded))\n",
        "print(len(data_eng),len(tweet_eng),len(one_hot_encoded_eng))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1942 1942 1942\n",
            "1903 1903 1903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYMfSnxoLw0M"
      },
      "source": [
        "window_length = 72\n",
        "n_features = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9TRZzFwUFY4"
      },
      "source": [
        "def get_word_vector(word):\n",
        "    embedding_vector = z.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        return embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcCjkI58VGx7"
      },
      "source": [
        "# get_word_vector('thetftfft')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr9rZOMOQmO7"
      },
      "source": [
        "def text_to_vector(text):\n",
        "    \n",
        "    words = trivial_tokenize(text)\n",
        "\n",
        "    window = words[:window_length]\n",
        "    \n",
        "    x = np.zeros((window_length, n_features))\n",
        "\n",
        "    for i, word in enumerate(window):\n",
        "        if get_word_vector(word) is not None:\n",
        "            x[i, :] = get_word_vector(word).astype('float32')\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be5hDUT1VixC"
      },
      "source": [
        "def df_to_data(df,tw):\n",
        "    \n",
        "    x = np.zeros((len(df), window_length, n_features), dtype='float32')\n",
        "\n",
        "    for i, comment in enumerate(tw):\n",
        "        x[i, :] = text_to_vector(comment)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95t5qER0Vja_"
      },
      "source": [
        "X_data_hi = df_to_data(combined_df,tweet)\n",
        "X_data_en = df_to_data(data_eng,tweet_eng)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqYG9I_nV5iY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "31f0d507-0ce4-4ed4-e13b-7503a1de23f0"
      },
      "source": [
        "X_data_hi.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1942, 72, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0grXQJN5Z-Hy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4c03e54e-dd83-42b5-f438-272f1d035b0f"
      },
      "source": [
        "X_data_en.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1903, 72, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TEf3TxGaaYy"
      },
      "source": [
        "X_data = np.concatenate((X_data_hi, X_data_en), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubqjxERIan5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dbb3075c-181c-48fb-bdba-1b0a5cd8af27"
      },
      "source": [
        "X_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3845, 72, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbe6XlsDapie"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_hi = [to_categorical(i, num_classes=2) for i in one_hot_encoded]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRbWPdKwa4Yt"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_en = [to_categorical(i, num_classes=2) for i in one_hot_encoded_eng]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gceF3kIa7G5"
      },
      "source": [
        "y_hi = np.asarray(y_hi)\n",
        "y_en = np.asarray(y_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iQ9NvaubIDX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "06c19c1a-40eb-4d31-a8c7-09c04b5bf2b0"
      },
      "source": [
        "y_hi.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1942, 72, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKOC1YpYbLKd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6726e015-3277-44d2-c2e7-432529f076ed"
      },
      "source": [
        "y_en.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1903, 72, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1noV7lTUbMOF"
      },
      "source": [
        "y_data = np.concatenate((y_hi,y_en),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0sojK3FbX49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ce4ed6a6-ffcc-4d58-d15a-b1009be5df6b"
      },
      "source": [
        "y_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3845, 72, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0pgZhuTbc1p"
      },
      "source": [
        "# Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82f3s3VXbgIv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7f7504be-d674-48b8-fecc-511b3ea8cd3b"
      },
      "source": [
        "'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\\nprint(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEHcWaMiU9dM"
      },
      "source": [
        "# Install keras contrib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scKtYcodU9Dl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "37ec2b2c-bf9c-44a3-f514-7d6999832095"
      },
      "source": [
        "cd /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz5iKAoSVH4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "82024828-8bbb-4169-f1a1-d97977417a7c"
      },
      "source": [
        "!git clone https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-contrib'...\n",
            "warning: redirecting to https://github.com/keras-team/keras-contrib.git/\n",
            "remote: Enumerating objects: 3634, done.\u001b[K\n",
            "remote: Total 3634 (delta 0), reused 0 (delta 0), pack-reused 3634\u001b[K\n",
            "Receiving objects: 100% (3634/3634), 861.24 KiB | 8.20 MiB/s, done.\n",
            "Resolving deltas: 100% (2330/2330), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAraQPgtVOgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5bfca390-e838-4998-966b-1a6be4b9426d"
      },
      "source": [
        "cd keras-contrib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-contrib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJzxwVb3VRqQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8df0e5e-b0e9-432f-d767-368c88244801"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating keras_contrib.egg-info\n",
            "writing keras_contrib.egg-info/PKG-INFO\n",
            "writing dependency_links to keras_contrib.egg-info/dependency_links.txt\n",
            "writing requirements to keras_contrib.egg-info/requires.txt\n",
            "writing top-level names to keras_contrib.egg-info/top_level.txt\n",
            "writing manifest file 'keras_contrib.egg-info/SOURCES.txt'\n",
            "writing manifest file 'keras_contrib.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/keras_contrib\n",
            "copying keras_contrib/__init__.py -> build/lib/keras_contrib\n",
            "creating build/lib/keras_contrib/layers\n",
            "copying keras_contrib/layers/capsule.py -> build/lib/keras_contrib/layers\n",
            "copying keras_contrib/layers/core.py -> build/lib/keras_contrib/layers\n",
            "copying keras_contrib/layers/__init__.py -> build/lib/keras_contrib/layers\n",
            "copying keras_contrib/layers/crf.py -> build/lib/keras_contrib/layers\n",
            "creating build/lib/keras_contrib/applications\n",
            "copying keras_contrib/applications/resnet.py -> build/lib/keras_contrib/applications\n",
            "copying keras_contrib/applications/nasnet.py -> build/lib/keras_contrib/applications\n",
            "copying keras_contrib/applications/densenet.py -> build/lib/keras_contrib/applications\n",
            "copying keras_contrib/applications/wide_resnet.py -> build/lib/keras_contrib/applications\n",
            "copying keras_contrib/applications/__init__.py -> build/lib/keras_contrib/applications\n",
            "creating build/lib/keras_contrib/utils\n",
            "copying keras_contrib/utils/save_load_utils.py -> build/lib/keras_contrib/utils\n",
            "copying keras_contrib/utils/conv_utils.py -> build/lib/keras_contrib/utils\n",
            "copying keras_contrib/utils/__init__.py -> build/lib/keras_contrib/utils\n",
            "copying keras_contrib/utils/test_utils.py -> build/lib/keras_contrib/utils\n",
            "creating build/lib/keras_contrib/backend\n",
            "copying keras_contrib/backend/numpy_backend.py -> build/lib/keras_contrib/backend\n",
            "copying keras_contrib/backend/cntk_backend.py -> build/lib/keras_contrib/backend\n",
            "copying keras_contrib/backend/tensorflow_backend.py -> build/lib/keras_contrib/backend\n",
            "copying keras_contrib/backend/__init__.py -> build/lib/keras_contrib/backend\n",
            "copying keras_contrib/backend/theano_backend.py -> build/lib/keras_contrib/backend\n",
            "creating build/lib/keras_contrib/wrappers\n",
            "copying keras_contrib/wrappers/__init__.py -> build/lib/keras_contrib/wrappers\n",
            "creating build/lib/keras_contrib/optimizers\n",
            "copying keras_contrib/optimizers/ftml.py -> build/lib/keras_contrib/optimizers\n",
            "copying keras_contrib/optimizers/lars.py -> build/lib/keras_contrib/optimizers\n",
            "copying keras_contrib/optimizers/yogi.py -> build/lib/keras_contrib/optimizers\n",
            "copying keras_contrib/optimizers/__init__.py -> build/lib/keras_contrib/optimizers\n",
            "copying keras_contrib/optimizers/padam.py -> build/lib/keras_contrib/optimizers\n",
            "creating build/lib/keras_contrib/activations\n",
            "copying keras_contrib/activations/squash.py -> build/lib/keras_contrib/activations\n",
            "copying keras_contrib/activations/__init__.py -> build/lib/keras_contrib/activations\n",
            "creating build/lib/keras_contrib/constraints\n",
            "copying keras_contrib/constraints/clip.py -> build/lib/keras_contrib/constraints\n",
            "copying keras_contrib/constraints/__init__.py -> build/lib/keras_contrib/constraints\n",
            "creating build/lib/keras_contrib/initializers\n",
            "copying keras_contrib/initializers/__init__.py -> build/lib/keras_contrib/initializers\n",
            "copying keras_contrib/initializers/convaware.py -> build/lib/keras_contrib/initializers\n",
            "creating build/lib/keras_contrib/callbacks\n",
            "copying keras_contrib/callbacks/cyclical_learning_rate.py -> build/lib/keras_contrib/callbacks\n",
            "copying keras_contrib/callbacks/tensorboard.py -> build/lib/keras_contrib/callbacks\n",
            "copying keras_contrib/callbacks/__init__.py -> build/lib/keras_contrib/callbacks\n",
            "copying keras_contrib/callbacks/snapshot.py -> build/lib/keras_contrib/callbacks\n",
            "copying keras_contrib/callbacks/dead_relu_detector.py -> build/lib/keras_contrib/callbacks\n",
            "creating build/lib/keras_contrib/losses\n",
            "copying keras_contrib/losses/dssim.py -> build/lib/keras_contrib/losses\n",
            "copying keras_contrib/losses/jaccard.py -> build/lib/keras_contrib/losses\n",
            "copying keras_contrib/losses/__init__.py -> build/lib/keras_contrib/losses\n",
            "copying keras_contrib/losses/crf_losses.py -> build/lib/keras_contrib/losses\n",
            "creating build/lib/keras_contrib/metrics\n",
            "copying keras_contrib/metrics/crf_accuracies.py -> build/lib/keras_contrib/metrics\n",
            "copying keras_contrib/metrics/__init__.py -> build/lib/keras_contrib/metrics\n",
            "creating build/lib/keras_contrib/preprocessing\n",
            "copying keras_contrib/preprocessing/__init__.py -> build/lib/keras_contrib/preprocessing\n",
            "creating build/lib/keras_contrib/tests\n",
            "copying keras_contrib/tests/activations.py -> build/lib/keras_contrib/tests\n",
            "copying keras_contrib/tests/metrics.py -> build/lib/keras_contrib/tests\n",
            "copying keras_contrib/tests/regularizers.py -> build/lib/keras_contrib/tests\n",
            "copying keras_contrib/tests/optimizers.py -> build/lib/keras_contrib/tests\n",
            "copying keras_contrib/tests/__init__.py -> build/lib/keras_contrib/tests\n",
            "creating build/lib/keras_contrib/regularizers\n",
            "copying keras_contrib/regularizers/__init__.py -> build/lib/keras_contrib/regularizers\n",
            "creating build/lib/keras_contrib/datasets\n",
            "copying keras_contrib/datasets/pascal_voc.py -> build/lib/keras_contrib/datasets\n",
            "copying keras_contrib/datasets/conll2000.py -> build/lib/keras_contrib/datasets\n",
            "copying keras_contrib/datasets/coco.py -> build/lib/keras_contrib/datasets\n",
            "copying keras_contrib/datasets/__init__.py -> build/lib/keras_contrib/datasets\n",
            "creating build/lib/keras_contrib/layers/convolutional\n",
            "copying keras_contrib/layers/convolutional/subpixelupscaling.py -> build/lib/keras_contrib/layers/convolutional\n",
            "copying keras_contrib/layers/convolutional/cosineconvolution2d.py -> build/lib/keras_contrib/layers/convolutional\n",
            "copying keras_contrib/layers/convolutional/__init__.py -> build/lib/keras_contrib/layers/convolutional\n",
            "creating build/lib/keras_contrib/layers/advanced_activations\n",
            "copying keras_contrib/layers/advanced_activations/swish.py -> build/lib/keras_contrib/layers/advanced_activations\n",
            "copying keras_contrib/layers/advanced_activations/sinerelu.py -> build/lib/keras_contrib/layers/advanced_activations\n",
            "copying keras_contrib/layers/advanced_activations/pelu.py -> build/lib/keras_contrib/layers/advanced_activations\n",
            "copying keras_contrib/layers/advanced_activations/srelu.py -> build/lib/keras_contrib/layers/advanced_activations\n",
            "copying keras_contrib/layers/advanced_activations/__init__.py -> build/lib/keras_contrib/layers/advanced_activations\n",
            "creating build/lib/keras_contrib/layers/normalization\n",
            "copying keras_contrib/layers/normalization/instancenormalization.py -> build/lib/keras_contrib/layers/normalization\n",
            "copying keras_contrib/layers/normalization/__init__.py -> build/lib/keras_contrib/layers/normalization\n",
            "copying keras_contrib/layers/normalization/groupnormalization.py -> build/lib/keras_contrib/layers/normalization\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/layers\n",
            "copying build/lib/keras_contrib/layers/capsule.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/layers/convolutional\n",
            "copying build/lib/keras_contrib/layers/convolutional/subpixelupscaling.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/convolutional\n",
            "copying build/lib/keras_contrib/layers/convolutional/cosineconvolution2d.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/convolutional\n",
            "copying build/lib/keras_contrib/layers/convolutional/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/convolutional\n",
            "copying build/lib/keras_contrib/layers/core.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations\n",
            "copying build/lib/keras_contrib/layers/advanced_activations/swish.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations\n",
            "copying build/lib/keras_contrib/layers/advanced_activations/sinerelu.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations\n",
            "copying build/lib/keras_contrib/layers/advanced_activations/pelu.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations\n",
            "copying build/lib/keras_contrib/layers/advanced_activations/srelu.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations\n",
            "copying build/lib/keras_contrib/layers/advanced_activations/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/layers/normalization\n",
            "copying build/lib/keras_contrib/layers/normalization/instancenormalization.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/normalization\n",
            "copying build/lib/keras_contrib/layers/normalization/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/normalization\n",
            "copying build/lib/keras_contrib/layers/normalization/groupnormalization.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers/normalization\n",
            "copying build/lib/keras_contrib/layers/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers\n",
            "copying build/lib/keras_contrib/layers/crf.py -> build/bdist.linux-x86_64/egg/keras_contrib/layers\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/applications\n",
            "copying build/lib/keras_contrib/applications/resnet.py -> build/bdist.linux-x86_64/egg/keras_contrib/applications\n",
            "copying build/lib/keras_contrib/applications/nasnet.py -> build/bdist.linux-x86_64/egg/keras_contrib/applications\n",
            "copying build/lib/keras_contrib/applications/densenet.py -> build/bdist.linux-x86_64/egg/keras_contrib/applications\n",
            "copying build/lib/keras_contrib/applications/wide_resnet.py -> build/bdist.linux-x86_64/egg/keras_contrib/applications\n",
            "copying build/lib/keras_contrib/applications/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/applications\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/utils\n",
            "copying build/lib/keras_contrib/utils/save_load_utils.py -> build/bdist.linux-x86_64/egg/keras_contrib/utils\n",
            "copying build/lib/keras_contrib/utils/conv_utils.py -> build/bdist.linux-x86_64/egg/keras_contrib/utils\n",
            "copying build/lib/keras_contrib/utils/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/utils\n",
            "copying build/lib/keras_contrib/utils/test_utils.py -> build/bdist.linux-x86_64/egg/keras_contrib/utils\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/backend\n",
            "copying build/lib/keras_contrib/backend/numpy_backend.py -> build/bdist.linux-x86_64/egg/keras_contrib/backend\n",
            "copying build/lib/keras_contrib/backend/cntk_backend.py -> build/bdist.linux-x86_64/egg/keras_contrib/backend\n",
            "copying build/lib/keras_contrib/backend/tensorflow_backend.py -> build/bdist.linux-x86_64/egg/keras_contrib/backend\n",
            "copying build/lib/keras_contrib/backend/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/backend\n",
            "copying build/lib/keras_contrib/backend/theano_backend.py -> build/bdist.linux-x86_64/egg/keras_contrib/backend\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/wrappers\n",
            "copying build/lib/keras_contrib/wrappers/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/wrappers\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/optimizers\n",
            "copying build/lib/keras_contrib/optimizers/ftml.py -> build/bdist.linux-x86_64/egg/keras_contrib/optimizers\n",
            "copying build/lib/keras_contrib/optimizers/lars.py -> build/bdist.linux-x86_64/egg/keras_contrib/optimizers\n",
            "copying build/lib/keras_contrib/optimizers/yogi.py -> build/bdist.linux-x86_64/egg/keras_contrib/optimizers\n",
            "copying build/lib/keras_contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/optimizers\n",
            "copying build/lib/keras_contrib/optimizers/padam.py -> build/bdist.linux-x86_64/egg/keras_contrib/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/activations\n",
            "copying build/lib/keras_contrib/activations/squash.py -> build/bdist.linux-x86_64/egg/keras_contrib/activations\n",
            "copying build/lib/keras_contrib/activations/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/activations\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/constraints\n",
            "copying build/lib/keras_contrib/constraints/clip.py -> build/bdist.linux-x86_64/egg/keras_contrib/constraints\n",
            "copying build/lib/keras_contrib/constraints/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/constraints\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/initializers\n",
            "copying build/lib/keras_contrib/initializers/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/initializers\n",
            "copying build/lib/keras_contrib/initializers/convaware.py -> build/bdist.linux-x86_64/egg/keras_contrib/initializers\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/callbacks\n",
            "copying build/lib/keras_contrib/callbacks/cyclical_learning_rate.py -> build/bdist.linux-x86_64/egg/keras_contrib/callbacks\n",
            "copying build/lib/keras_contrib/callbacks/tensorboard.py -> build/bdist.linux-x86_64/egg/keras_contrib/callbacks\n",
            "copying build/lib/keras_contrib/callbacks/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/callbacks\n",
            "copying build/lib/keras_contrib/callbacks/snapshot.py -> build/bdist.linux-x86_64/egg/keras_contrib/callbacks\n",
            "copying build/lib/keras_contrib/callbacks/dead_relu_detector.py -> build/bdist.linux-x86_64/egg/keras_contrib/callbacks\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/losses\n",
            "copying build/lib/keras_contrib/losses/dssim.py -> build/bdist.linux-x86_64/egg/keras_contrib/losses\n",
            "copying build/lib/keras_contrib/losses/jaccard.py -> build/bdist.linux-x86_64/egg/keras_contrib/losses\n",
            "copying build/lib/keras_contrib/losses/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/losses\n",
            "copying build/lib/keras_contrib/losses/crf_losses.py -> build/bdist.linux-x86_64/egg/keras_contrib/losses\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/metrics\n",
            "copying build/lib/keras_contrib/metrics/crf_accuracies.py -> build/bdist.linux-x86_64/egg/keras_contrib/metrics\n",
            "copying build/lib/keras_contrib/metrics/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/metrics\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/preprocessing\n",
            "copying build/lib/keras_contrib/preprocessing/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/preprocessing\n",
            "copying build/lib/keras_contrib/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/tests\n",
            "copying build/lib/keras_contrib/tests/activations.py -> build/bdist.linux-x86_64/egg/keras_contrib/tests\n",
            "copying build/lib/keras_contrib/tests/metrics.py -> build/bdist.linux-x86_64/egg/keras_contrib/tests\n",
            "copying build/lib/keras_contrib/tests/regularizers.py -> build/bdist.linux-x86_64/egg/keras_contrib/tests\n",
            "copying build/lib/keras_contrib/tests/optimizers.py -> build/bdist.linux-x86_64/egg/keras_contrib/tests\n",
            "copying build/lib/keras_contrib/tests/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/tests\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/regularizers\n",
            "copying build/lib/keras_contrib/regularizers/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/regularizers\n",
            "creating build/bdist.linux-x86_64/egg/keras_contrib/datasets\n",
            "copying build/lib/keras_contrib/datasets/pascal_voc.py -> build/bdist.linux-x86_64/egg/keras_contrib/datasets\n",
            "copying build/lib/keras_contrib/datasets/conll2000.py -> build/bdist.linux-x86_64/egg/keras_contrib/datasets\n",
            "copying build/lib/keras_contrib/datasets/coco.py -> build/bdist.linux-x86_64/egg/keras_contrib/datasets\n",
            "copying build/lib/keras_contrib/datasets/__init__.py -> build/bdist.linux-x86_64/egg/keras_contrib/datasets\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/capsule.py to capsule.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/convolutional/subpixelupscaling.py to subpixelupscaling.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/convolutional/cosineconvolution2d.py to cosineconvolution2d.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/convolutional/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/core.py to core.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations/swish.py to swish.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations/sinerelu.py to sinerelu.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations/pelu.py to pelu.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations/srelu.py to srelu.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/advanced_activations/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/normalization/instancenormalization.py to instancenormalization.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/normalization/groupnormalization.py to groupnormalization.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/layers/crf.py to crf.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/applications/resnet.py to resnet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/applications/nasnet.py to nasnet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/applications/densenet.py to densenet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/applications/wide_resnet.py to wide_resnet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/applications/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/utils/save_load_utils.py to save_load_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/utils/conv_utils.py to conv_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/utils/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/utils/test_utils.py to test_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/backend/numpy_backend.py to numpy_backend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/backend/cntk_backend.py to cntk_backend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/backend/tensorflow_backend.py to tensorflow_backend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/backend/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/backend/theano_backend.py to theano_backend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/wrappers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/optimizers/ftml.py to ftml.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/optimizers/lars.py to lars.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/optimizers/yogi.py to yogi.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/optimizers/padam.py to padam.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/activations/squash.py to squash.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/activations/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/constraints/clip.py to clip.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/constraints/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/initializers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/initializers/convaware.py to convaware.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/callbacks/cyclical_learning_rate.py to cyclical_learning_rate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/callbacks/tensorboard.py to tensorboard.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/callbacks/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/callbacks/snapshot.py to snapshot.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/callbacks/dead_relu_detector.py to dead_relu_detector.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/losses/dssim.py to dssim.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/losses/jaccard.py to jaccard.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/losses/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/losses/crf_losses.py to crf_losses.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/metrics/crf_accuracies.py to crf_accuracies.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/metrics/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/preprocessing/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/tests/activations.py to activations.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/tests/metrics.py to metrics.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/tests/regularizers.py to regularizers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/tests/optimizers.py to optimizers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/tests/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/regularizers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/datasets/pascal_voc.py to pascal_voc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/datasets/conll2000.py to conll2000.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/datasets/coco.py to coco.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_contrib/datasets/__init__.py to __init__.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_contrib.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_contrib.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_contrib.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_contrib.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_contrib.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/keras_contrib-2.0.8-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing keras_contrib-2.0.8-py3.6.egg\n",
            "Copying keras_contrib-2.0.8-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding keras-contrib 2.0.8 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/keras_contrib-2.0.8-py3.6.egg\n",
            "Processing dependencies for keras-contrib==2.0.8\n",
            "Searching for Keras==2.3.1\n",
            "Best match: Keras 2.3.1\n",
            "Adding Keras 2.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.18.2\n",
            "Best match: numpy 1.18.2\n",
            "Adding numpy 1.18.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for PyYAML==3.13\n",
            "Best match: PyYAML 3.13\n",
            "Adding PyYAML 3.13 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for h5py==2.10.0\n",
            "Best match: h5py 2.10.0\n",
            "Adding h5py 2.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Applications==1.0.8\n",
            "Best match: Keras-Applications 1.0.8\n",
            "Adding Keras-Applications 1.0.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Preprocessing==1.1.0\n",
            "Best match: Keras-Preprocessing 1.1.0\n",
            "Adding Keras-Preprocessing 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for keras-contrib==2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHaeiiFPc2aq"
      },
      "source": [
        "# Model2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS53_615jcU4"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "\n",
        "def plot_AUC_ROC(y_true, y_pred):\n",
        "    n_classes = 2\n",
        "\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "############################################################################################\n",
        "    lw = 2\n",
        "    # Compute macro-average ROC curve and ROC area\n",
        "\n",
        "    # First aggregate all false positive rates\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "    # Then interpolate all ROC curves at this points\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for i in range(n_classes):\n",
        "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "    # Finally average it and compute AUC\n",
        "    mean_tpr /= n_classes\n",
        "\n",
        "    fpr[\"macro\"] = all_fpr\n",
        "    tpr[\"macro\"] = mean_tpr\n",
        "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "    # Plot all ROC curves\n",
        "    plt.figure()\n",
        "    '''\n",
        "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "            label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "            color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "            label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "            color='navy', linestyle=':', linewidth=4)\n",
        "    '''\n",
        "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "    #classes_list1 = [\"DE\",\"NE\",\"DK\"]\n",
        "    classes_list1 = [\"other\",\"disaster_place\"]\n",
        "    for i, color,c in zip(range(n_classes), colors,classes_list1):\n",
        "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "                label='{0} (AUC = {1:0.2f})'\n",
        "                ''.format(c, roc_auc[i]))\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    #plt.show()\n",
        "\n",
        "    # Plot of a ROC curve for a specific class\n",
        "    '''\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr[0], tpr[0], color='darkorange',\n",
        "            lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVUG4Cj1Uxzu"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Greys):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j],fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"red\" if cm[i, j] > thresh else \"red\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZyB_RP4U1_u"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import reduce\n",
        "def report_average(*args):\n",
        "    report_list = list()\n",
        "    for report in args:\n",
        "        splited = [' '.join(x.split()) for x in report.split('\\n')]\n",
        "        splited = [x for x in splited if x != '']  \n",
        "        splited[1:3] = [' '.join(splited[1:3])]\n",
        "        del splited[2:4]\n",
        "        #del splited[-1]\n",
        "        #print(splited)\n",
        "        header = [x for x in splited[0].split(' ')]\n",
        "        #print(header)\n",
        "        data = np.array(splited[1].split(' ')).reshape(-1, len(header) + 1)\n",
        "        #print(data)\n",
        "        data = np.delete(data, 0, 1).astype(float)\n",
        "        #print(data)\n",
        "        avg_total = np.array([x for x in splited[2].split(' ')][2:]).astype(float).reshape(-1, len(header))\n",
        "        df = pd.DataFrame(np.concatenate((data, avg_total)), columns=header)\n",
        "        report_list.append(df)\n",
        "    res = reduce(lambda x, y: x.add(y, fill_value=0), report_list) / len(report_list)\n",
        "    return res.rename(index={res.index[-1]: 'weighted avg'})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDuLll8tVHMm"
      },
      "source": [
        "###########Definining Embedding Layer for neural network\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import LSTM, Dense, Input, Flatten,Bidirectional,Dropout, concatenate,Concatenate\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Activation, RepeatVector, SimpleRNN, GRU,TimeDistributed\n",
        "from sklearn import metrics\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.layers.core import Permute\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "from keras_contrib.layers.crf import CRF\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def create_model_cnn():\n",
        "    model = None\n",
        "    convs = []\n",
        "\n",
        "    input_i = Input(shape=(72,300,),dtype='float32')\n",
        "    filter_sizes = [1,2,3]\n",
        "    ############For different size filters\n",
        "    for fsz in filter_sizes:\n",
        "        x = Conv1D(nb_filter=256,filter_length=fsz,activation='relu',padding=\"same\")(input_i)\n",
        "        convs.append(x)\n",
        "    x = Concatenate()(convs)\n",
        "    x = Conv1D(128, 2, activation='relu', padding=\"same\")(x)\n",
        "    x = Conv1D(64, 2, activation ='relu', padding =\"same\")(x)\n",
        "    x = CRF(2, learn_mode = 'marginal')(x)\n",
        "    #preds = TimeDistributed(Dense(2, activation=\"sigmoid\"))(x)\n",
        "    model = Model(input_i, x)\n",
        "    crf_layer = CRF(2, learn_mode = 'marginal')\n",
        "    # compile the model\n",
        "    model.compile(optimizer='adam', loss=crf_layer.loss_function, metrics=[crf_layer.accuracy])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxJbv1uFU6qe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c3919ef-1770-49f2-c49a-7d328adf8ab5"
      },
      "source": [
        "# applying k-fold\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42) \n",
        "#kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "Class_report_result= []\n",
        "accuracy_score_result =[]\n",
        "ROC_AUC_score_result = []\n",
        "\n",
        "i = 1\n",
        "for train, test in kf.split(X_data):\n",
        "    print(y_data[train].shape)\n",
        "    print(y_data[test].shape)\n",
        "    print(X_data[train].shape)\n",
        "    print(X_data[test].shape)\n",
        "\n",
        "\n",
        "    filepath=\"/content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best\"+str(i)+\"K_fold.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "    callbacks_list = [checkpoint]\n",
        "    model = create_model_cnn()\n",
        "    model.fit(X_data[train], y_data[train] ,validation_data=(X_data[test], y_data[test]), epochs = 50,batch_size=32,callbacks=callbacks_list, verbose = 2)\n",
        "    \n",
        "\n",
        "    print('best weight loding...')\n",
        "    model.load_weights(filepath)\n",
        "    print('best weight loaded')\n",
        "\n",
        "    p = model.predict(np.array(X_data[test]))\n",
        "\n",
        "   \n",
        "    print(classification_report(np.argmax(y_data[test], 2).ravel(), np.argmax(p, axis=2).ravel(),labels=[0,1], target_names=[\"other\",\"disaster_place\"]))\n",
        "    Class_report = classification_report(np.argmax(y_data[test], 2).ravel(), np.argmax(p, axis=2).ravel(),labels=[0,1], target_names=[\"other\",\"disaster_place\"])\n",
        "    Class_report_result.append(Class_report)\n",
        "\n",
        "\n",
        "    '''\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    print(\"Accuracy score =\", accuracy_score(label_test,predictions_test1))\n",
        "    accuracy_score_result.append(accuracy_score(label_test,predictions_test1))\n",
        "\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    print(\"ROC_AUC score =\", roc_auc_score(label_test,predictions_test))\n",
        "    ROC_AUC_score_result.append(roc_auc_score(label_test,predictions_test))\n",
        "    '''\n",
        "    plt.clf()\n",
        "    cnf_matrix = metrics.confusion_matrix(np.argmax(y_data[test],2).ravel(),np.argmax(p, axis =2).ravel())\n",
        "    #print(cnf_matrix)\n",
        "    plot_confusion_matrix(cnf_matrix, classes = [\"other\",\"disaster_place\"], normalize = True)\n",
        "    #plt.show()\n",
        "\n",
        "    \n",
        "    plt.savefig(\"/content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Confusion_1-2-3-2-2_layer_CNN_best\"+str(i)+\"k_fold.pdf\", format = 'pdf', dpi =1000, bbox_inches = 'tight')\n",
        "\n",
        "    plt.clf()\n",
        "    plot_AUC_ROC(np.argmax(y_data[test],2), np.argmax(p, axis =2))\n",
        "    plt.savefig(\"/content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/ROC_1-2-3-2-2_layer_CNN_best\"+str(i)+\"K_fold.pdf\", format = 'pdf', dpi =1000, bbox_inches = 'tight')\n",
        " \n",
        "    i=i+1\n",
        "\n",
        "# the function 'report_average' is used to do the average of all the classification report coming from K-fold\n",
        "report_ave = report_average(Class_report_result[0],Class_report_result[1], Class_report_result[2], Class_report_result[3], Class_report_result[4])\n",
        "\n",
        "print (Class_report_result[0])\n",
        "print (Class_report_result[1])\n",
        "print (Class_report_result[2])\n",
        "print (Class_report_result[3])\n",
        "print (Class_report_result[4])\n",
        "\n",
        "print (report_ave)\n",
        "\n",
        "#print(\"Average accuracy score = \", np.mean(accuracy_score_result))\n",
        "\n",
        "#print(\"Average ROC AUC score = \", np.mean(ROC_AUC_score_result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3076, 72, 2)\n",
            "(769, 72, 2)\n",
            "(3076, 72, 300)\n",
            "(769, 72, 300)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=1)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=2)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=3)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:2403: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/keras-contrib/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/content/keras-contrib/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 3076 samples, validate on 769 samples\n",
            "Epoch 1/50\n",
            " - 12s - loss: 0.2926 - crf_marginal_accuracy: 0.8936 - val_loss: 0.0481 - val_crf_marginal_accuracy: 0.9827\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.04807, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best1K_fold.hdf5\n",
            "Epoch 2/50\n",
            " - 12s - loss: 0.0316 - crf_marginal_accuracy: 0.9892 - val_loss: 0.0260 - val_crf_marginal_accuracy: 0.9913\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.04807 to 0.02602, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best1K_fold.hdf5\n",
            "Epoch 3/50\n",
            " - 12s - loss: 0.0210 - crf_marginal_accuracy: 0.9930 - val_loss: 0.0237 - val_crf_marginal_accuracy: 0.9921\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.02602 to 0.02374, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best1K_fold.hdf5\n",
            "Epoch 4/50\n",
            " - 12s - loss: 0.0169 - crf_marginal_accuracy: 0.9942 - val_loss: 0.0222 - val_crf_marginal_accuracy: 0.9926\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.02374 to 0.02216, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best1K_fold.hdf5\n",
            "Epoch 5/50\n",
            " - 11s - loss: 0.0140 - crf_marginal_accuracy: 0.9955 - val_loss: 0.0220 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.02216 to 0.02202, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best1K_fold.hdf5\n",
            "Epoch 6/50\n",
            " - 11s - loss: 0.0118 - crf_marginal_accuracy: 0.9962 - val_loss: 0.0235 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.02202\n",
            "Epoch 7/50\n",
            " - 11s - loss: 0.0104 - crf_marginal_accuracy: 0.9966 - val_loss: 0.0229 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.02202\n",
            "Epoch 8/50\n",
            " - 11s - loss: 0.0089 - crf_marginal_accuracy: 0.9972 - val_loss: 0.0242 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.02202\n",
            "Epoch 9/50\n",
            " - 12s - loss: 0.0080 - crf_marginal_accuracy: 0.9975 - val_loss: 0.0250 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.02202\n",
            "Epoch 10/50\n",
            " - 12s - loss: 0.0072 - crf_marginal_accuracy: 0.9977 - val_loss: 0.0269 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.02202\n",
            "Epoch 11/50\n",
            " - 11s - loss: 0.0066 - crf_marginal_accuracy: 0.9980 - val_loss: 0.0257 - val_crf_marginal_accuracy: 0.9932\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.02202\n",
            "Epoch 12/50\n",
            " - 11s - loss: 0.0059 - crf_marginal_accuracy: 0.9981 - val_loss: 0.0278 - val_crf_marginal_accuracy: 0.9925\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.02202\n",
            "Epoch 13/50\n",
            " - 11s - loss: 0.0056 - crf_marginal_accuracy: 0.9983 - val_loss: 0.0275 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.02202\n",
            "Epoch 14/50\n",
            " - 11s - loss: 0.0051 - crf_marginal_accuracy: 0.9984 - val_loss: 0.0273 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.02202\n",
            "Epoch 15/50\n",
            " - 11s - loss: 0.0047 - crf_marginal_accuracy: 0.9985 - val_loss: 0.0274 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.02202\n",
            "Epoch 16/50\n",
            " - 11s - loss: 0.0045 - crf_marginal_accuracy: 0.9986 - val_loss: 0.0297 - val_crf_marginal_accuracy: 0.9932\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.02202\n",
            "Epoch 17/50\n",
            " - 11s - loss: 0.0042 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0296 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.02202\n",
            "Epoch 18/50\n",
            " - 11s - loss: 0.0040 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0300 - val_crf_marginal_accuracy: 0.9917\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.02202\n",
            "Epoch 19/50\n",
            " - 11s - loss: 0.0038 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0297 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.02202\n",
            "Epoch 20/50\n",
            " - 11s - loss: 0.0034 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0307 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.02202\n",
            "Epoch 21/50\n",
            " - 11s - loss: 0.0033 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0321 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.02202\n",
            "Epoch 22/50\n",
            " - 11s - loss: 0.0031 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0332 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.02202\n",
            "Epoch 23/50\n",
            " - 11s - loss: 0.0030 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0357 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.02202\n",
            "Epoch 24/50\n",
            " - 11s - loss: 0.0029 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0375 - val_crf_marginal_accuracy: 0.9925\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.02202\n",
            "Epoch 25/50\n",
            " - 11s - loss: 0.0031 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0331 - val_crf_marginal_accuracy: 0.9929\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.02202\n",
            "Epoch 26/50\n",
            " - 11s - loss: 0.0027 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0375 - val_crf_marginal_accuracy: 0.9932\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.02202\n",
            "Epoch 27/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0349 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.02202\n",
            "Epoch 28/50\n",
            " - 11s - loss: 0.0024 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0386 - val_crf_marginal_accuracy: 0.9929\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.02202\n",
            "Epoch 29/50\n",
            " - 11s - loss: 0.0025 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0439 - val_crf_marginal_accuracy: 0.9920\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.02202\n",
            "Epoch 30/50\n",
            " - 11s - loss: 0.0041 - crf_marginal_accuracy: 0.9986 - val_loss: 0.0394 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.02202\n",
            "Epoch 31/50\n",
            " - 11s - loss: 0.0029 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0415 - val_crf_marginal_accuracy: 0.9923\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.02202\n",
            "Epoch 32/50\n",
            " - 11s - loss: 0.0030 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0381 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.02202\n",
            "Epoch 33/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0425 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.02202\n",
            "Epoch 34/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0408 - val_crf_marginal_accuracy: 0.9929\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.02202\n",
            "Epoch 35/50\n",
            " - 11s - loss: 0.0029 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0431 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.02202\n",
            "Epoch 36/50\n",
            " - 11s - loss: 0.0024 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0471 - val_crf_marginal_accuracy: 0.9921\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.02202\n",
            "Epoch 37/50\n",
            " - 12s - loss: 0.0029 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0425 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.02202\n",
            "Epoch 38/50\n",
            " - 11s - loss: 0.0024 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0450 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.02202\n",
            "Epoch 39/50\n",
            " - 11s - loss: 0.0021 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0473 - val_crf_marginal_accuracy: 0.9929\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.02202\n",
            "Epoch 40/50\n",
            " - 11s - loss: 0.0022 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0463 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.02202\n",
            "Epoch 41/50\n",
            " - 11s - loss: 0.0023 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0495 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.02202\n",
            "Epoch 42/50\n",
            " - 11s - loss: 0.0024 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0454 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.02202\n",
            "Epoch 43/50\n",
            " - 11s - loss: 0.0025 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0466 - val_crf_marginal_accuracy: 0.9925\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.02202\n",
            "Epoch 44/50\n",
            " - 11s - loss: 0.0023 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0479 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.02202\n",
            "Epoch 45/50\n",
            " - 11s - loss: 0.0037 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0465 - val_crf_marginal_accuracy: 0.9926\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.02202\n",
            "Epoch 46/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0474 - val_crf_marginal_accuracy: 0.9921\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.02202\n",
            "Epoch 47/50\n",
            " - 11s - loss: 0.0023 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0453 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.02202\n",
            "Epoch 48/50\n",
            " - 11s - loss: 0.0020 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0488 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.02202\n",
            "Epoch 49/50\n",
            " - 11s - loss: 0.0018 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0499 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.02202\n",
            "Epoch 50/50\n",
            " - 11s - loss: 0.0018 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0508 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.02202\n",
            "best weight loding...\n",
            "best weight loaded\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "         other       1.00      1.00      1.00     53960\n",
            "disaster_place       0.86      0.86      0.86      1408\n",
            "\n",
            "      accuracy                           0.99     55368\n",
            "     macro avg       0.93      0.93      0.93     55368\n",
            "  weighted avg       0.99      0.99      0.99     55368\n",
            "\n",
            "Normalized confusion matrix\n",
            "[[0.99638621 0.00361379]\n",
            " [0.14488636 0.85511364]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(3076, 72, 2)\n",
            "(769, 72, 2)\n",
            "(3076, 72, 300)\n",
            "(769, 72, 300)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=1)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=2)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=3)`\n",
            "/content/keras-contrib/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/content/keras-contrib/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3076 samples, validate on 769 samples\n",
            "Epoch 1/50\n",
            " - 12s - loss: 0.4199 - crf_marginal_accuracy: 0.8791 - val_loss: 0.1929 - val_crf_marginal_accuracy: 0.9836\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.19286, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best2K_fold.hdf5\n",
            "Epoch 2/50\n",
            " - 11s - loss: 0.0584 - crf_marginal_accuracy: 0.9877 - val_loss: 0.0265 - val_crf_marginal_accuracy: 0.9922\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.19286 to 0.02648, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best2K_fold.hdf5\n",
            "Epoch 3/50\n",
            " - 11s - loss: 0.0219 - crf_marginal_accuracy: 0.9924 - val_loss: 0.0226 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.02648 to 0.02256, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best2K_fold.hdf5\n",
            "Epoch 4/50\n",
            " - 11s - loss: 0.0173 - crf_marginal_accuracy: 0.9940 - val_loss: 0.0218 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.02256 to 0.02180, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best2K_fold.hdf5\n",
            "Epoch 5/50\n",
            " - 11s - loss: 0.0146 - crf_marginal_accuracy: 0.9949 - val_loss: 0.0221 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.02180\n",
            "Epoch 6/50\n",
            " - 11s - loss: 0.0125 - crf_marginal_accuracy: 0.9960 - val_loss: 0.0229 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.02180\n",
            "Epoch 7/50\n",
            " - 11s - loss: 0.0105 - crf_marginal_accuracy: 0.9966 - val_loss: 0.0232 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.02180\n",
            "Epoch 8/50\n",
            " - 11s - loss: 0.0093 - crf_marginal_accuracy: 0.9969 - val_loss: 0.0246 - val_crf_marginal_accuracy: 0.9929\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.02180\n",
            "Epoch 9/50\n",
            " - 11s - loss: 0.0080 - crf_marginal_accuracy: 0.9974 - val_loss: 0.0261 - val_crf_marginal_accuracy: 0.9926\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.02180\n",
            "Epoch 10/50\n",
            " - 11s - loss: 0.0074 - crf_marginal_accuracy: 0.9975 - val_loss: 0.0253 - val_crf_marginal_accuracy: 0.9932\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.02180\n",
            "Epoch 11/50\n",
            " - 11s - loss: 0.0068 - crf_marginal_accuracy: 0.9977 - val_loss: 0.0274 - val_crf_marginal_accuracy: 0.9922\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.02180\n",
            "Epoch 12/50\n",
            " - 11s - loss: 0.0061 - crf_marginal_accuracy: 0.9980 - val_loss: 0.0289 - val_crf_marginal_accuracy: 0.9924\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.02180\n",
            "Epoch 13/50\n",
            " - 11s - loss: 0.0055 - crf_marginal_accuracy: 0.9982 - val_loss: 0.0293 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.02180\n",
            "Epoch 14/50\n",
            " - 11s - loss: 0.0053 - crf_marginal_accuracy: 0.9982 - val_loss: 0.0307 - val_crf_marginal_accuracy: 0.9921\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.02180\n",
            "Epoch 15/50\n",
            " - 11s - loss: 0.0053 - crf_marginal_accuracy: 0.9982 - val_loss: 0.0311 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.02180\n",
            "Epoch 16/50\n",
            " - 11s - loss: 0.0045 - crf_marginal_accuracy: 0.9986 - val_loss: 0.0300 - val_crf_marginal_accuracy: 0.9925\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.02180\n",
            "Epoch 17/50\n",
            " - 11s - loss: 0.0041 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0327 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.02180\n",
            "Epoch 18/50\n",
            " - 11s - loss: 0.0042 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0340 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.02180\n",
            "Epoch 19/50\n",
            " - 11s - loss: 0.0037 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0341 - val_crf_marginal_accuracy: 0.9924\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.02180\n",
            "Epoch 20/50\n",
            " - 11s - loss: 0.0035 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0348 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.02180\n",
            "Epoch 21/50\n",
            " - 11s - loss: 0.0034 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0353 - val_crf_marginal_accuracy: 0.9929\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.02180\n",
            "Epoch 22/50\n",
            " - 11s - loss: 0.0033 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0356 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.02180\n",
            "Epoch 23/50\n",
            " - 11s - loss: 0.0031 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0347 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.02180\n",
            "Epoch 24/50\n",
            " - 11s - loss: 0.0029 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0374 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.02180\n",
            "Epoch 25/50\n",
            " - 11s - loss: 0.0029 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0395 - val_crf_marginal_accuracy: 0.9926\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.02180\n",
            "Epoch 26/50\n",
            " - 11s - loss: 0.0029 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0394 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.02180\n",
            "Epoch 27/50\n",
            " - 11s - loss: 0.0028 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0424 - val_crf_marginal_accuracy: 0.9922\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.02180\n",
            "Epoch 28/50\n",
            " - 11s - loss: 0.0027 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0444 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.02180\n",
            "Epoch 29/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0424 - val_crf_marginal_accuracy: 0.9926\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.02180\n",
            "Epoch 30/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0414 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.02180\n",
            "Epoch 31/50\n",
            " - 11s - loss: 0.0039 - crf_marginal_accuracy: 0.9986 - val_loss: 0.0403 - val_crf_marginal_accuracy: 0.9924\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.02180\n",
            "Epoch 32/50\n",
            " - 11s - loss: 0.0030 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0431 - val_crf_marginal_accuracy: 0.9923\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.02180\n",
            "Epoch 33/50\n",
            " - 12s - loss: 0.0028 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0448 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.02180\n",
            "Epoch 34/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0465 - val_crf_marginal_accuracy: 0.9925\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.02180\n",
            "Epoch 35/50\n",
            " - 11s - loss: 0.0025 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0462 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.02180\n",
            "Epoch 36/50\n",
            " - 11s - loss: 0.0024 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0469 - val_crf_marginal_accuracy: 0.9923\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.02180\n",
            "Epoch 37/50\n",
            " - 11s - loss: 0.0023 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0494 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.02180\n",
            "Epoch 38/50\n",
            " - 11s - loss: 0.0024 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0465 - val_crf_marginal_accuracy: 0.9925\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.02180\n",
            "Epoch 39/50\n",
            " - 11s - loss: 0.0024 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0497 - val_crf_marginal_accuracy: 0.9925\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.02180\n",
            "Epoch 40/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0544 - val_crf_marginal_accuracy: 0.9919\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.02180\n",
            "Epoch 41/50\n",
            " - 12s - loss: 0.0026 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0547 - val_crf_marginal_accuracy: 0.9923\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.02180\n",
            "Epoch 42/50\n",
            " - 11s - loss: 0.0038 - crf_marginal_accuracy: 0.9986 - val_loss: 0.0451 - val_crf_marginal_accuracy: 0.9924\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.02180\n",
            "Epoch 43/50\n",
            " - 11s - loss: 0.0029 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0494 - val_crf_marginal_accuracy: 0.9924\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.02180\n",
            "Epoch 44/50\n",
            " - 11s - loss: 0.0024 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0518 - val_crf_marginal_accuracy: 0.9925\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.02180\n",
            "Epoch 45/50\n",
            " - 11s - loss: 0.0022 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0481 - val_crf_marginal_accuracy: 0.9923\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.02180\n",
            "Epoch 46/50\n",
            " - 11s - loss: 0.0021 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0508 - val_crf_marginal_accuracy: 0.9924\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.02180\n",
            "Epoch 47/50\n",
            " - 11s - loss: 0.0020 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0540 - val_crf_marginal_accuracy: 0.9923\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.02180\n",
            "Epoch 48/50\n",
            " - 11s - loss: 0.0022 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0523 - val_crf_marginal_accuracy: 0.9921\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.02180\n",
            "Epoch 49/50\n",
            " - 11s - loss: 0.0020 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0494 - val_crf_marginal_accuracy: 0.9923\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.02180\n",
            "Epoch 50/50\n",
            " - 11s - loss: 0.0020 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0502 - val_crf_marginal_accuracy: 0.9923\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.02180\n",
            "best weight loding...\n",
            "best weight loaded\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "         other       1.00      1.00      1.00     54004\n",
            "disaster_place       0.85      0.86      0.85      1364\n",
            "\n",
            "      accuracy                           0.99     55368\n",
            "     macro avg       0.92      0.93      0.92     55368\n",
            "  weighted avg       0.99      0.99      0.99     55368\n",
            "\n",
            "Normalized confusion matrix\n",
            "[[0.99605585 0.00394415]\n",
            " [0.14002933 0.85997067]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(3076, 72, 2)\n",
            "(769, 72, 2)\n",
            "(3076, 72, 300)\n",
            "(769, 72, 300)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=1)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=2)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=3)`\n",
            "/content/keras-contrib/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/content/keras-contrib/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3076 samples, validate on 769 samples\n",
            "Epoch 1/50\n",
            " - 12s - loss: 0.1184 - crf_marginal_accuracy: 0.9440 - val_loss: 0.0296 - val_crf_marginal_accuracy: 0.9900\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02962, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best3K_fold.hdf5\n",
            "Epoch 2/50\n",
            " - 11s - loss: 0.0239 - crf_marginal_accuracy: 0.9920 - val_loss: 0.0223 - val_crf_marginal_accuracy: 0.9926\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02962 to 0.02231, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best3K_fold.hdf5\n",
            "Epoch 3/50\n",
            " - 11s - loss: 0.0179 - crf_marginal_accuracy: 0.9941 - val_loss: 0.0206 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.02231 to 0.02061, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best3K_fold.hdf5\n",
            "Epoch 4/50\n",
            " - 11s - loss: 0.0146 - crf_marginal_accuracy: 0.9949 - val_loss: 0.0216 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.02061\n",
            "Epoch 5/50\n",
            " - 11s - loss: 0.0114 - crf_marginal_accuracy: 0.9961 - val_loss: 0.0215 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.02061\n",
            "Epoch 6/50\n",
            " - 11s - loss: 0.0103 - crf_marginal_accuracy: 0.9966 - val_loss: 0.0225 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.02061\n",
            "Epoch 7/50\n",
            " - 11s - loss: 0.0086 - crf_marginal_accuracy: 0.9970 - val_loss: 0.0240 - val_crf_marginal_accuracy: 0.9937\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.02061\n",
            "Epoch 8/50\n",
            " - 11s - loss: 0.0073 - crf_marginal_accuracy: 0.9976 - val_loss: 0.0267 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.02061\n",
            "Epoch 9/50\n",
            " - 11s - loss: 0.0067 - crf_marginal_accuracy: 0.9979 - val_loss: 0.0260 - val_crf_marginal_accuracy: 0.9937\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.02061\n",
            "Epoch 10/50\n",
            " - 11s - loss: 0.0057 - crf_marginal_accuracy: 0.9982 - val_loss: 0.0282 - val_crf_marginal_accuracy: 0.9935\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.02061\n",
            "Epoch 11/50\n",
            " - 11s - loss: 0.0052 - crf_marginal_accuracy: 0.9983 - val_loss: 0.0282 - val_crf_marginal_accuracy: 0.9932\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.02061\n",
            "Epoch 12/50\n",
            " - 11s - loss: 0.0049 - crf_marginal_accuracy: 0.9985 - val_loss: 0.0290 - val_crf_marginal_accuracy: 0.9936\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.02061\n",
            "Epoch 13/50\n",
            " - 11s - loss: 0.0045 - crf_marginal_accuracy: 0.9986 - val_loss: 0.0306 - val_crf_marginal_accuracy: 0.9935\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.02061\n",
            "Epoch 14/50\n",
            " - 11s - loss: 0.0041 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0302 - val_crf_marginal_accuracy: 0.9937\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.02061\n",
            "Epoch 15/50\n",
            " - 11s - loss: 0.0042 - crf_marginal_accuracy: 0.9986 - val_loss: 0.0296 - val_crf_marginal_accuracy: 0.9932\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.02061\n",
            "Epoch 16/50\n",
            " - 11s - loss: 0.0037 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0312 - val_crf_marginal_accuracy: 0.9935\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.02061\n",
            "Epoch 17/50\n",
            " - 11s - loss: 0.0035 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0329 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.02061\n",
            "Epoch 18/50\n",
            " - 11s - loss: 0.0034 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0346 - val_crf_marginal_accuracy: 0.9935\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.02061\n",
            "Epoch 19/50\n",
            " - 11s - loss: 0.0031 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0310 - val_crf_marginal_accuracy: 0.9935\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.02061\n",
            "Epoch 20/50\n",
            " - 11s - loss: 0.0034 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0363 - val_crf_marginal_accuracy: 0.9935\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.02061\n",
            "Epoch 21/50\n",
            " - 11s - loss: 0.0028 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0375 - val_crf_marginal_accuracy: 0.9935\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.02061\n",
            "Epoch 22/50\n",
            " - 11s - loss: 0.0029 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0350 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.02061\n",
            "Epoch 23/50\n",
            " - 11s - loss: 0.0028 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0375 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.02061\n",
            "Epoch 24/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0385 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.02061\n",
            "Epoch 25/50\n",
            " - 11s - loss: 0.0024 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0398 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.02061\n",
            "Epoch 26/50\n",
            " - 11s - loss: 0.0023 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0404 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.02061\n",
            "Epoch 27/50\n",
            " - 11s - loss: 0.0023 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0414 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.02061\n",
            "Epoch 28/50\n",
            " - 11s - loss: 0.0023 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0423 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.02061\n",
            "Epoch 29/50\n",
            " - 12s - loss: 0.0020 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0447 - val_crf_marginal_accuracy: 0.9932\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.02061\n",
            "Epoch 30/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0438 - val_crf_marginal_accuracy: 0.9929\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.02061\n",
            "Epoch 31/50\n",
            " - 11s - loss: 0.0028 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0427 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.02061\n",
            "Epoch 32/50\n",
            " - 11s - loss: 0.0035 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0393 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.02061\n",
            "Epoch 33/50\n",
            " - 11s - loss: 0.0031 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0414 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.02061\n",
            "Epoch 34/50\n",
            " - 11s - loss: 0.0032 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0409 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.02061\n",
            "Epoch 35/50\n",
            " - 11s - loss: 0.0022 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0428 - val_crf_marginal_accuracy: 0.9925\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.02061\n",
            "Epoch 36/50\n",
            " - 11s - loss: 0.0020 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0423 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.02061\n",
            "Epoch 37/50\n",
            " - 11s - loss: 0.0019 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0461 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.02061\n",
            "Epoch 38/50\n",
            " - 11s - loss: 0.0017 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0472 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.02061\n",
            "Epoch 39/50\n",
            " - 11s - loss: 0.0017 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0467 - val_crf_marginal_accuracy: 0.9924\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.02061\n",
            "Epoch 40/50\n",
            " - 11s - loss: 0.0017 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0509 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.02061\n",
            "Epoch 41/50\n",
            " - 11s - loss: 0.0016 - crf_marginal_accuracy: 0.9993 - val_loss: 0.0529 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.02061\n",
            "Epoch 42/50\n",
            " - 11s - loss: 0.0017 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0536 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.02061\n",
            "Epoch 43/50\n",
            " - 11s - loss: 0.0016 - crf_marginal_accuracy: 0.9993 - val_loss: 0.0512 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.02061\n",
            "Epoch 44/50\n",
            " - 11s - loss: 0.0017 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0512 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.02061\n",
            "Epoch 45/50\n",
            " - 12s - loss: 0.0022 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0520 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.02061\n",
            "Epoch 46/50\n",
            " - 11s - loss: 0.0037 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0446 - val_crf_marginal_accuracy: 0.9918\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.02061\n",
            "Epoch 47/50\n",
            " - 11s - loss: 0.0029 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0481 - val_crf_marginal_accuracy: 0.9929\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.02061\n",
            "Epoch 48/50\n",
            " - 11s - loss: 0.0027 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0421 - val_crf_marginal_accuracy: 0.9932\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.02061\n",
            "Epoch 49/50\n",
            " - 11s - loss: 0.0021 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0491 - val_crf_marginal_accuracy: 0.9932\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.02061\n",
            "Epoch 50/50\n",
            " - 11s - loss: 0.0020 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0461 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.02061\n",
            "best weight loding...\n",
            "best weight loaded\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "         other       1.00      1.00      1.00     53934\n",
            "disaster_place       0.88      0.85      0.86      1434\n",
            "\n",
            "      accuracy                           0.99     55368\n",
            "     macro avg       0.94      0.92      0.93     55368\n",
            "  weighted avg       0.99      0.99      0.99     55368\n",
            "\n",
            "Normalized confusion matrix\n",
            "[[0.99692216 0.00307784]\n",
            " [0.14993026 0.85006974]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(3076, 72, 2)\n",
            "(769, 72, 2)\n",
            "(3076, 72, 300)\n",
            "(769, 72, 300)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=1)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=2)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=3)`\n",
            "/content/keras-contrib/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/content/keras-contrib/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3076 samples, validate on 769 samples\n",
            "Epoch 1/50\n",
            " - 12s - loss: 0.4285 - crf_marginal_accuracy: 0.8594 - val_loss: 0.1474 - val_crf_marginal_accuracy: 0.9850\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.14742, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best4K_fold.hdf5\n",
            "Epoch 2/50\n",
            " - 11s - loss: 0.0367 - crf_marginal_accuracy: 0.9892 - val_loss: 0.0255 - val_crf_marginal_accuracy: 0.9917\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.14742 to 0.02548, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best4K_fold.hdf5\n",
            "Epoch 3/50\n",
            " - 11s - loss: 0.0210 - crf_marginal_accuracy: 0.9930 - val_loss: 0.0240 - val_crf_marginal_accuracy: 0.9922\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.02548 to 0.02401, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best4K_fold.hdf5\n",
            "Epoch 4/50\n",
            " - 11s - loss: 0.0167 - crf_marginal_accuracy: 0.9944 - val_loss: 0.0215 - val_crf_marginal_accuracy: 0.9929\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.02401 to 0.02153, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best4K_fold.hdf5\n",
            "Epoch 5/50\n",
            " - 11s - loss: 0.0138 - crf_marginal_accuracy: 0.9955 - val_loss: 0.0227 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.02153\n",
            "Epoch 6/50\n",
            " - 11s - loss: 0.0115 - crf_marginal_accuracy: 0.9962 - val_loss: 0.0223 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.02153\n",
            "Epoch 7/50\n",
            " - 11s - loss: 0.0096 - crf_marginal_accuracy: 0.9968 - val_loss: 0.0229 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.02153\n",
            "Epoch 8/50\n",
            " - 11s - loss: 0.0085 - crf_marginal_accuracy: 0.9971 - val_loss: 0.0239 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.02153\n",
            "Epoch 9/50\n",
            " - 11s - loss: 0.0076 - crf_marginal_accuracy: 0.9975 - val_loss: 0.0253 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.02153\n",
            "Epoch 10/50\n",
            " - 11s - loss: 0.0075 - crf_marginal_accuracy: 0.9976 - val_loss: 0.0255 - val_crf_marginal_accuracy: 0.9924\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.02153\n",
            "Epoch 11/50\n",
            " - 11s - loss: 0.0061 - crf_marginal_accuracy: 0.9980 - val_loss: 0.0287 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.02153\n",
            "Epoch 12/50\n",
            " - 11s - loss: 0.0059 - crf_marginal_accuracy: 0.9981 - val_loss: 0.0269 - val_crf_marginal_accuracy: 0.9925\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.02153\n",
            "Epoch 13/50\n",
            " - 11s - loss: 0.0052 - crf_marginal_accuracy: 0.9983 - val_loss: 0.0287 - val_crf_marginal_accuracy: 0.9929\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.02153\n",
            "Epoch 14/50\n",
            " - 11s - loss: 0.0050 - crf_marginal_accuracy: 0.9985 - val_loss: 0.0302 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.02153\n",
            "Epoch 15/50\n",
            " - 11s - loss: 0.0049 - crf_marginal_accuracy: 0.9983 - val_loss: 0.0304 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.02153\n",
            "Epoch 16/50\n",
            " - 11s - loss: 0.0044 - crf_marginal_accuracy: 0.9985 - val_loss: 0.0287 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.02153\n",
            "Epoch 17/50\n",
            " - 11s - loss: 0.0041 - crf_marginal_accuracy: 0.9986 - val_loss: 0.0310 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.02153\n",
            "Epoch 18/50\n",
            " - 11s - loss: 0.0039 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0328 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.02153\n",
            "Epoch 19/50\n",
            " - 11s - loss: 0.0040 - crf_marginal_accuracy: 0.9985 - val_loss: 0.0322 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.02153\n",
            "Epoch 20/50\n",
            " - 11s - loss: 0.0048 - crf_marginal_accuracy: 0.9983 - val_loss: 0.0316 - val_crf_marginal_accuracy: 0.9924\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.02153\n",
            "Epoch 21/50\n",
            " - 11s - loss: 0.0037 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0344 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.02153\n",
            "Epoch 22/50\n",
            " - 11s - loss: 0.0034 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0340 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.02153\n",
            "Epoch 23/50\n",
            " - 11s - loss: 0.0031 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0352 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.02153\n",
            "Epoch 24/50\n",
            " - 11s - loss: 0.0029 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0334 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.02153\n",
            "Epoch 25/50\n",
            " - 11s - loss: 0.0028 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0391 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.02153\n",
            "Epoch 26/50\n",
            " - 11s - loss: 0.0029 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0384 - val_crf_marginal_accuracy: 0.9926\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.02153\n",
            "Epoch 27/50\n",
            " - 11s - loss: 0.0027 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0403 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.02153\n",
            "Epoch 28/50\n",
            " - 11s - loss: 0.0027 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0411 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.02153\n",
            "Epoch 29/50\n",
            " - 11s - loss: 0.0025 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0417 - val_crf_marginal_accuracy: 0.9924\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.02153\n",
            "Epoch 30/50\n",
            " - 11s - loss: 0.0025 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0397 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.02153\n",
            "Epoch 31/50\n",
            " - 11s - loss: 0.0024 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0457 - val_crf_marginal_accuracy: 0.9929\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.02153\n",
            "Epoch 32/50\n",
            " - 11s - loss: 0.0024 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0457 - val_crf_marginal_accuracy: 0.9925\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.02153\n",
            "Epoch 33/50\n",
            " - 11s - loss: 0.0025 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0452 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.02153\n",
            "Epoch 34/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0412 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.02153\n",
            "Epoch 35/50\n",
            " - 11s - loss: 0.0032 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0409 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.02153\n",
            "Epoch 36/50\n",
            " - 11s - loss: 0.0034 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0389 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.02153\n",
            "Epoch 37/50\n",
            " - 11s - loss: 0.0030 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0426 - val_crf_marginal_accuracy: 0.9922\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.02153\n",
            "Epoch 38/50\n",
            " - 11s - loss: 0.0027 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0450 - val_crf_marginal_accuracy: 0.9926\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.02153\n",
            "Epoch 39/50\n",
            " - 11s - loss: 0.0023 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0429 - val_crf_marginal_accuracy: 0.9926\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.02153\n",
            "Epoch 40/50\n",
            " - 11s - loss: 0.0022 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0440 - val_crf_marginal_accuracy: 0.9925\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.02153\n",
            "Epoch 41/50\n",
            " - 11s - loss: 0.0020 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0508 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.02153\n",
            "Epoch 42/50\n",
            " - 11s - loss: 0.0020 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0495 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.02153\n",
            "Epoch 43/50\n",
            " - 11s - loss: 0.0019 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0475 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.02153\n",
            "Epoch 44/50\n",
            " - 11s - loss: 0.0019 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0507 - val_crf_marginal_accuracy: 0.9926\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.02153\n",
            "Epoch 45/50\n",
            " - 11s - loss: 0.0021 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0466 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.02153\n",
            "Epoch 46/50\n",
            " - 11s - loss: 0.0020 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0488 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.02153\n",
            "Epoch 47/50\n",
            " - 11s - loss: 0.0020 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0516 - val_crf_marginal_accuracy: 0.9928\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.02153\n",
            "Epoch 48/50\n",
            " - 11s - loss: 0.0021 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0482 - val_crf_marginal_accuracy: 0.9925\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.02153\n",
            "Epoch 49/50\n",
            " - 11s - loss: 0.0022 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0489 - val_crf_marginal_accuracy: 0.9925\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.02153\n",
            "Epoch 50/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0498 - val_crf_marginal_accuracy: 0.9927\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.02153\n",
            "best weight loding...\n",
            "best weight loaded\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "         other       1.00      1.00      1.00     53966\n",
            "disaster_place       0.85      0.86      0.85      1402\n",
            "\n",
            "      accuracy                           0.99     55368\n",
            "     macro avg       0.92      0.93      0.93     55368\n",
            "  weighted avg       0.99      0.99      0.99     55368\n",
            "\n",
            "Normalized confusion matrix\n",
            "[[0.99599748 0.00400252]\n",
            " [0.13908702 0.86091298]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(3076, 72, 2)\n",
            "(769, 72, 2)\n",
            "(3076, 72, 300)\n",
            "(769, 72, 300)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=1)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=2)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", padding=\"same\", filters=256, kernel_size=3)`\n",
            "/content/keras-contrib/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/content/keras-contrib/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3076 samples, validate on 769 samples\n",
            "Epoch 1/50\n",
            " - 12s - loss: 0.4519 - crf_marginal_accuracy: 0.8606 - val_loss: 0.1908 - val_crf_marginal_accuracy: 0.9822\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.19078, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best5K_fold.hdf5\n",
            "Epoch 2/50\n",
            " - 11s - loss: 0.0780 - crf_marginal_accuracy: 0.9864 - val_loss: 0.0255 - val_crf_marginal_accuracy: 0.9912\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.19078 to 0.02549, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best5K_fold.hdf5\n",
            "Epoch 3/50\n",
            " - 11s - loss: 0.0232 - crf_marginal_accuracy: 0.9921 - val_loss: 0.0211 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.02549 to 0.02106, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best5K_fold.hdf5\n",
            "Epoch 4/50\n",
            " - 11s - loss: 0.0184 - crf_marginal_accuracy: 0.9937 - val_loss: 0.0200 - val_crf_marginal_accuracy: 0.9935\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.02106 to 0.02004, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best5K_fold.hdf5\n",
            "Epoch 5/50\n",
            " - 11s - loss: 0.0153 - crf_marginal_accuracy: 0.9948 - val_loss: 0.0195 - val_crf_marginal_accuracy: 0.9936\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.02004 to 0.01949, saving model to /content/gdrive/My Drive/Phd_implementation/Location_multilingual/Final_models/Bi_lingual/CNN/CNN_1-2-3-2-2-256-128-64/Weight_1-2-3-2-2_CNN_best5K_fold.hdf5\n",
            "Epoch 6/50\n",
            " - 11s - loss: 0.0127 - crf_marginal_accuracy: 0.9960 - val_loss: 0.0199 - val_crf_marginal_accuracy: 0.9939\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01949\n",
            "Epoch 7/50\n",
            " - 11s - loss: 0.0106 - crf_marginal_accuracy: 0.9965 - val_loss: 0.0209 - val_crf_marginal_accuracy: 0.9939\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.01949\n",
            "Epoch 8/50\n",
            " - 11s - loss: 0.0091 - crf_marginal_accuracy: 0.9971 - val_loss: 0.0223 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.01949\n",
            "Epoch 9/50\n",
            " - 11s - loss: 0.0083 - crf_marginal_accuracy: 0.9974 - val_loss: 0.0213 - val_crf_marginal_accuracy: 0.9937\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01949\n",
            "Epoch 10/50\n",
            " - 11s - loss: 0.0071 - crf_marginal_accuracy: 0.9977 - val_loss: 0.0237 - val_crf_marginal_accuracy: 0.9937\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01949\n",
            "Epoch 11/50\n",
            " - 11s - loss: 0.0066 - crf_marginal_accuracy: 0.9979 - val_loss: 0.0249 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01949\n",
            "Epoch 12/50\n",
            " - 11s - loss: 0.0059 - crf_marginal_accuracy: 0.9981 - val_loss: 0.0241 - val_crf_marginal_accuracy: 0.9937\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01949\n",
            "Epoch 13/50\n",
            " - 11s - loss: 0.0059 - crf_marginal_accuracy: 0.9981 - val_loss: 0.0254 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01949\n",
            "Epoch 14/50\n",
            " - 11s - loss: 0.0052 - crf_marginal_accuracy: 0.9984 - val_loss: 0.0299 - val_crf_marginal_accuracy: 0.9918\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.01949\n",
            "Epoch 15/50\n",
            " - 11s - loss: 0.0050 - crf_marginal_accuracy: 0.9984 - val_loss: 0.0272 - val_crf_marginal_accuracy: 0.9936\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01949\n",
            "Epoch 16/50\n",
            " - 11s - loss: 0.0048 - crf_marginal_accuracy: 0.9984 - val_loss: 0.0282 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01949\n",
            "Epoch 17/50\n",
            " - 11s - loss: 0.0042 - crf_marginal_accuracy: 0.9985 - val_loss: 0.0280 - val_crf_marginal_accuracy: 0.9937\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01949\n",
            "Epoch 18/50\n",
            " - 11s - loss: 0.0044 - crf_marginal_accuracy: 0.9986 - val_loss: 0.0295 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01949\n",
            "Epoch 19/50\n",
            " - 11s - loss: 0.0039 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0284 - val_crf_marginal_accuracy: 0.9935\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.01949\n",
            "Epoch 20/50\n",
            " - 11s - loss: 0.0035 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0298 - val_crf_marginal_accuracy: 0.9937\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01949\n",
            "Epoch 21/50\n",
            " - 11s - loss: 0.0034 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0306 - val_crf_marginal_accuracy: 0.9935\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01949\n",
            "Epoch 22/50\n",
            " - 11s - loss: 0.0031 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0314 - val_crf_marginal_accuracy: 0.9936\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.01949\n",
            "Epoch 23/50\n",
            " - 11s - loss: 0.0031 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0337 - val_crf_marginal_accuracy: 0.9935\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01949\n",
            "Epoch 24/50\n",
            " - 11s - loss: 0.0029 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0362 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01949\n",
            "Epoch 25/50\n",
            " - 11s - loss: 0.0031 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0352 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01949\n",
            "Epoch 26/50\n",
            " - 11s - loss: 0.0027 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0369 - val_crf_marginal_accuracy: 0.9932\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01949\n",
            "Epoch 27/50\n",
            " - 11s - loss: 0.0027 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0375 - val_crf_marginal_accuracy: 0.9932\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01949\n",
            "Epoch 28/50\n",
            " - 11s - loss: 0.0034 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0360 - val_crf_marginal_accuracy: 0.9935\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01949\n",
            "Epoch 29/50\n",
            " - 11s - loss: 0.0028 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0361 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01949\n",
            "Epoch 30/50\n",
            " - 11s - loss: 0.0028 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0378 - val_crf_marginal_accuracy: 0.9936\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01949\n",
            "Epoch 31/50\n",
            " - 11s - loss: 0.0027 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0392 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01949\n",
            "Epoch 32/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0362 - val_crf_marginal_accuracy: 0.9934\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01949\n",
            "Epoch 33/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0393 - val_crf_marginal_accuracy: 0.9929\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01949\n",
            "Epoch 34/50\n",
            " - 11s - loss: 0.0027 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0392 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01949\n",
            "Epoch 35/50\n",
            " - 11s - loss: 0.0031 - crf_marginal_accuracy: 0.9989 - val_loss: 0.0415 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01949\n",
            "Epoch 36/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0430 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01949\n",
            "Epoch 37/50\n",
            " - 11s - loss: 0.0026 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0431 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01949\n",
            "Epoch 38/50\n",
            " - 11s - loss: 0.0025 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0458 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01949\n",
            "Epoch 39/50\n",
            " - 11s - loss: 0.0035 - crf_marginal_accuracy: 0.9987 - val_loss: 0.0445 - val_crf_marginal_accuracy: 0.9932\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01949\n",
            "Epoch 40/50\n",
            " - 11s - loss: 0.0027 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0451 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01949\n",
            "Epoch 41/50\n",
            " - 11s - loss: 0.0023 - crf_marginal_accuracy: 0.9990 - val_loss: 0.0434 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01949\n",
            "Epoch 42/50\n",
            " - 11s - loss: 0.0021 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0487 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01949\n",
            "Epoch 43/50\n",
            " - 11s - loss: 0.0020 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0469 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.01949\n",
            "Epoch 44/50\n",
            " - 11s - loss: 0.0020 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0482 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01949\n",
            "Epoch 45/50\n",
            " - 11s - loss: 0.0019 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0482 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.01949\n",
            "Epoch 46/50\n",
            " - 11s - loss: 0.0018 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0485 - val_crf_marginal_accuracy: 0.9933\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.01949\n",
            "Epoch 47/50\n",
            " - 11s - loss: 0.0019 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0510 - val_crf_marginal_accuracy: 0.9932\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.01949\n",
            "Epoch 48/50\n",
            " - 11s - loss: 0.0019 - crf_marginal_accuracy: 0.9991 - val_loss: 0.0522 - val_crf_marginal_accuracy: 0.9931\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.01949\n",
            "Epoch 49/50\n",
            " - 11s - loss: 0.0019 - crf_marginal_accuracy: 0.9992 - val_loss: 0.0532 - val_crf_marginal_accuracy: 0.9932\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.01949\n",
            "Epoch 50/50\n",
            " - 11s - loss: 0.0025 - crf_marginal_accuracy: 0.9988 - val_loss: 0.0498 - val_crf_marginal_accuracy: 0.9930\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.01949\n",
            "best weight loding...\n",
            "best weight loaded\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "         other       1.00      1.00      1.00     53957\n",
            "disaster_place       0.88      0.86      0.87      1411\n",
            "\n",
            "      accuracy                           0.99     55368\n",
            "     macro avg       0.94      0.93      0.93     55368\n",
            "  weighted avg       0.99      0.99      0.99     55368\n",
            "\n",
            "Normalized confusion matrix\n",
            "[[0.99679374 0.00320626]\n",
            " [0.14032601 0.85967399]]\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "         other       1.00      1.00      1.00     53960\n",
            "disaster_place       0.86      0.86      0.86      1408\n",
            "\n",
            "      accuracy                           0.99     55368\n",
            "     macro avg       0.93      0.93      0.93     55368\n",
            "  weighted avg       0.99      0.99      0.99     55368\n",
            "\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "         other       1.00      1.00      1.00     54004\n",
            "disaster_place       0.85      0.86      0.85      1364\n",
            "\n",
            "      accuracy                           0.99     55368\n",
            "     macro avg       0.92      0.93      0.92     55368\n",
            "  weighted avg       0.99      0.99      0.99     55368\n",
            "\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "         other       1.00      1.00      1.00     53934\n",
            "disaster_place       0.88      0.85      0.86      1434\n",
            "\n",
            "      accuracy                           0.99     55368\n",
            "     macro avg       0.94      0.92      0.93     55368\n",
            "  weighted avg       0.99      0.99      0.99     55368\n",
            "\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "         other       1.00      1.00      1.00     53966\n",
            "disaster_place       0.85      0.86      0.85      1402\n",
            "\n",
            "      accuracy                           0.99     55368\n",
            "     macro avg       0.92      0.93      0.93     55368\n",
            "  weighted avg       0.99      0.99      0.99     55368\n",
            "\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "         other       1.00      1.00      1.00     53957\n",
            "disaster_place       0.88      0.86      0.87      1411\n",
            "\n",
            "      accuracy                           0.99     55368\n",
            "     macro avg       0.94      0.93      0.93     55368\n",
            "  weighted avg       0.99      0.99      0.99     55368\n",
            "\n",
            "              precision  recall  f1-score  support\n",
            "0                 1.000   1.000     1.000  53964.2\n",
            "1                 0.864   0.858     0.858   1403.8\n",
            "weighted avg      0.990   0.990     0.990  55368.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4wPsKseIpmD"
      },
      "source": [
        "## Manual Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6UAtSshIstA"
      },
      "source": [
        "def check_model2(tweet):\n",
        "    text = preprocess_tweet(tweet)\n",
        "    \n",
        "    x = np.zeros((1, window_length, n_features), dtype='float32')\n",
        "    x[0, :] = text_to_vector(text)\n",
        "    \n",
        "    \n",
        "    p = model4.predict(x)\n",
        "\n",
        "    op = (np.argmax(p, axis=2))\n",
        "    i = 0\n",
        "    \n",
        "    for word in trivial_tokenize(text):\n",
        "        print(word,':',op[0][i])\n",
        "        i+=1\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43sd3qlSJFlt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6a0d60d0-1097-4344-9175-174a780059a5"
      },
      "source": [
        "check_model2('State of natural disaster declared as extreme flooding displaces 50 000 in Congo')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "State : 0\n",
            "of : 0\n",
            "natural : 0\n",
            "disaster : 0\n",
            "declared : 0\n",
            "as : 0\n",
            "extreme : 0\n",
            "flooding : 0\n",
            "displaces : 0\n",
            "50 : 0\n",
            "000 : 0\n",
            "in : 0\n",
            "Congo : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbzNdCnXANhH"
      },
      "source": [
        "'''\n",
        "def check_model3(tweet):\n",
        "\n",
        "    text = preprocess_tweet(tweet)\n",
        " \n",
        "    x = np.zeros((1, window_length, n_features), dtype='float32')\n",
        "    x[0, :] = text_to_vector(text)\n",
        "    \n",
        "    p = model4.predict(x)\n",
        "\n",
        "    op = (np.argmax(p, axis=2))\n",
        "    \n",
        "    return op[0]\n",
        "'''  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yY7ThirKggR"
      },
      "source": [
        "'''\n",
        "tweet_joined = tweet + tweet_eng\n",
        "one_hot_encoded_joined = one_hot_encoded + one_hot_encoded_eng\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDZvAU_2veyU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "8e73581d-a785-4c94-e112-f1cbd4fdbf2f"
      },
      "source": [
        "check_model2('महाराष्ट्र  केरल  गुजरात  कर्नाटक और मध्य प्रदेश में भारी बारिश और बाढ़ की वजह से  160 से अधिक लोगों की मौत बेहद दुखद है। एनडीआरएफ  वायुसेना और नेवी ने लाखों लोगों को सुरक्षित स्थानों पर पहुंचाया है। ईश्वर से बाढ़ प्रभावित लोगों के सुरक्षित रहने की कामना करता हूं।')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "महाराष्ट्र : 1\n",
            "केरल : 1\n",
            "गुजरात : 0\n",
            "कर्नाटक : 1\n",
            "और : 0\n",
            "मध्य : 0\n",
            "प्रदेश : 0\n",
            "में : 0\n",
            "भारी : 0\n",
            "बारिश : 0\n",
            "और : 0\n",
            "बाढ़ : 0\n",
            "की : 0\n",
            "वजह : 0\n",
            "से : 0\n",
            "160 : 0\n",
            "से : 0\n",
            "अधिक : 0\n",
            "लोगों : 0\n",
            "की : 0\n",
            "मौत : 0\n",
            "बेहद : 0\n",
            "दुखद : 0\n",
            "है : 0\n",
            "। : 0\n",
            "एनडीआरएफ : 0\n",
            "वायुसेना : 0\n",
            "और : 0\n",
            "नेवी : 1\n",
            "ने : 0\n",
            "लाखों : 0\n",
            "लोगों : 0\n",
            "को : 0\n",
            "सुरक्षित : 0\n",
            "स्थानों : 0\n",
            "पर : 0\n",
            "पहुंचाया : 0\n",
            "है : 0\n",
            "। : 0\n",
            "ईश्वर : 0\n",
            "से : 0\n",
            "बाढ़ : 0\n",
            "प्रभावित : 0\n",
            "लोगों : 0\n",
            "के : 0\n",
            "सुरक्षित : 0\n",
            "रहने : 0\n",
            "की : 0\n",
            "कामना : 0\n",
            "करता : 0\n",
            "हूं : 0\n",
            "। : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMM3hGWsqSLU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d63d99bc-994f-42df-f703-34a67a0c5018"
      },
      "source": [
        "check_model2(\"moderate earthquake kuril islands 16 january at 10 am\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "moderate : 0\n",
            "earthquake : 0\n",
            "kuril : 1\n",
            "islands : 1\n",
            "16 : 0\n",
            "january : 0\n",
            "at : 0\n",
            "10 : 0\n",
            "am : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dg-C0A7TwrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "d38e311a-af84-4a07-f638-45a7243d12f6"
      },
      "source": [
        "check_model2(\"#Dorian 'डोरियन तूफान के बाद जल  खाद्य सहायता  आश्रय और संचार की आवश्यकताएं बहामास के लोगों की मदद कर रही यूएन एजेंसियों की सर्वोच्च मानवीय प्राथमिकताएं हैं'\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "डोरियन : 0\n",
            "तूफान : 0\n",
            "के : 0\n",
            "बाद : 0\n",
            "जल : 0\n",
            "खाद्य : 0\n",
            "सहायता : 0\n",
            "आश्रय : 0\n",
            "और : 0\n",
            "संचार : 0\n",
            "की : 0\n",
            "आवश्यकताएं : 0\n",
            "बहामास : 1\n",
            "के : 0\n",
            "लोगों : 0\n",
            "की : 0\n",
            "मदद : 0\n",
            "कर : 0\n",
            "रही : 0\n",
            "यूएन : 0\n",
            "एजेंसियों : 0\n",
            "की : 0\n",
            "सर्वोच्च : 0\n",
            "मानवीय : 0\n",
            "प्राथमिकताएं : 0\n",
            "हैं : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vuVpTeeDw6w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "a909fc0d-2e41-4bed-ee87-a12e48b1ed6f"
      },
      "source": [
        "check_model2(\"earthquake sismo m strikes km sw of laguna niguel california 30 min ago more info\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "earthquake : 0\n",
            "sismo : 0\n",
            "m : 0\n",
            "strikes : 0\n",
            "km : 0\n",
            "sw : 0\n",
            "of : 0\n",
            "laguna : 1\n",
            "niguel : 1\n",
            "california : 1\n",
            "30 : 0\n",
            "min : 0\n",
            "ago : 0\n",
            "more : 0\n",
            "info : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJzi2WDPDw25"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpWrnMPrgWDT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}